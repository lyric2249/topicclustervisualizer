{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "48e74dbe-c206-448b-80a9-0681c286706e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\n",
      "   0.8635   0.6455   1.2309   0.3664\n",
      "   0.9823   0.7291   1.3008   0.7792\n",
      "   1.0882   1.0004   1.6399   0.6935\n",
      "   1.4101   0.9859   2.0146   0.7092\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from pyarma import *\n",
    "\n",
    "A = mat(4, 5, fill.randu)\n",
    "B = mat(4, 5, fill.randu)\n",
    "  \n",
    "C = A*B.t()\n",
    "\n",
    "C.print(\"C:\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1c592be3-68d5-4393-b7ce-78ac88898d4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<pyarma.pyarma.mat object at 00000236C32F9850>\n",
      "[matrix size: 3x2]\n",
      "   0.2358   0.9341\n",
      "   0.3640   0.9989\n",
      "   0.3630   0.2010\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<pyarma.pyarma.mat object at 00000236C32F9850>\n",
       "[matrix size: 5x4]\n",
       "   0.2358   0.2010        0        0\n",
       "   0.3640        0        0        0\n",
       "   0.3630        0        0        0\n",
       "   0.9341        0        0        0\n",
       "   0.9989        0        0        0"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = mat(3, 2, fill.randu);\n",
    "\n",
    "print(A)\n",
    "\n",
    "A.reshape(5,4)\n",
    "\n",
    "A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "da6a4a97-3f83-4682-aa9f-342e5231c55a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<pyarma.pyarma.mat object at 00000236C32F9B90>\n",
      "[matrix size: 3x2]\n",
      "   0.1295   0.5738\n",
      "   0.3725   0.5908\n",
      "   0.9607   0.5239\n",
      "\n",
      "<pyarma.pyarma.mat object at 00000236C32F9B90>\n",
      "[matrix size: 5x5]\n",
      "   0.1295   0.5738        0        0        0\n",
      "   0.3725   0.5908        0        0        0\n",
      "   0.9607   0.5239        0        0        0\n",
      "        0        0        0        0        0\n",
      "        0        0        0        0        0\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<pyarma.pyarma.__subview_mat object at 0000023703792990>\n",
       "[matrix size: 5x2]\n",
       "   0.5738        0\n",
       "   0.5908        0\n",
       "   0.5239        0\n",
       "        0        0\n",
       "        0        0"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = mat(3, 2, fill.randu);\n",
    "\n",
    "print(A)\n",
    "\n",
    "A.resize(5,5);\n",
    "\n",
    "print(A)\n",
    "\n",
    "A[:,1:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "579c469e-8849-4a23-9987-5f08be718fad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e1289f44-65de-4c1e-8c01-e7c61908ccec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.37136221, 0.41697142, 0.50718125, 0.70331662, 0.56649942],\n",
       "       [0.62159117, 0.69808115, 0.47440331, 0.55340851, 0.44149835]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(np.random.uniform(0,1,10)).reshape((2,5))[0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "0cd96682-30dd-45c9-90eb-c030095cec06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2, 3]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[1,2,3,4,5][1:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "39e5b914-2201-41f6-adae-da578688b414",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9.99999999999998"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = 0\n",
    "for i in range(100):\n",
    "    x += .1\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "ba6ac563-3a4d-48c7-9e16-073bfadc1be9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1.00142163592215"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.log(randu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "93f9c144-e9aa-4b12-98bc-9afe8d236ba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "d8d07008-a48a-4baa-a052-c328d85c56f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('data_prob_90.csv', header=0, delim_whitespace=False)\n",
    "data_name = data.columns[1:]\n",
    "\n",
    "\n",
    "\n",
    "data = mat(np.array(data.iloc[:, 1:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "fb184aef-73dc-4494-8832-ce79a3287c05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pyarma.pyarma.cube object at 0000023703E26010>\n",
       "[cube size: 1x2x8]\n",
       "[cube slice: 0]\n",
       "   0.4281   0.7754\n",
       "\n",
       "[cube slice: 1]\n",
       "   0.0152   0.5220\n",
       "\n",
       "[cube slice: ...]\n",
       "\n",
       "[cube slice: 7]\n",
       "   0.5278   0.2344"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "randu(1,2,8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "3c17e6dc-2d81-4506-81e5-a97a4521236d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyarma import *\n",
    "from math import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "701474e1-2a39-4c10-be35-97dd9af93c68",
   "metadata": {},
   "outputs": [],
   "source": [
    "def onepl_lsrm_cont_missing(data,\n",
    "\n",
    "                            ndim,\n",
    "                            niter,\n",
    "                            nburn,\n",
    "                            nthin,\n",
    "                            nprint,\n",
    "\n",
    "                            jump_beta,\n",
    "                            jump_theta,\n",
    "                            jump_gamma,\n",
    "                            jump_z,\n",
    "                            jump_w,\n",
    "\n",
    "                            pr_mean_beta,\n",
    "                            pr_sd_beta,\n",
    "                            pr_a_th_sigma,\n",
    "                            pr_b_th_sigma,\n",
    "                            pr_mean_theta,\n",
    "\n",
    "                            pr_a_sigma,\n",
    "                            pr_b_sigma,\n",
    "                            pr_mean_gamma,\n",
    "                            pr_sd_gamma,\n",
    "\n",
    "                            missing):\n",
    "    ##############################################################################\n",
    "\n",
    "    def update_function(beta, theta, gamma):\n",
    "        return (- pow((data[k, i] - beta[i] - theta[k] + gamma * dist[k, i]), 2) /\n",
    "                (2 * pow(pr_sd, 2))\n",
    "                )\n",
    "\n",
    "    def rejection_algorithm(ratio):\n",
    "        if ratio > 0.0:\n",
    "            accept = 1\n",
    "        else:\n",
    "            un = randu()\n",
    "            if np.log(un) < ratio:\n",
    "                accept = 1\n",
    "            else:\n",
    "                accept = 0\n",
    "\n",
    "        return accept\n",
    "\n",
    "    ##############################################################################\n",
    "\n",
    "    #nsample = data.shape[0]\n",
    "    #nitem = data.shape[1]\n",
    "    \n",
    "    nsample = data.n_rows\n",
    "    nitem = data.n_cols\n",
    "\n",
    "    pr_mean_z = 0.0\n",
    "    pr_mean_w = 0.0\n",
    "\n",
    "    pr_sd_z = 1.0\n",
    "    pr_sd_w = 1.0\n",
    "    pr_sd = 1.0\n",
    "    pr_sd_theta = 1.0\n",
    "    \n",
    "    \"\"\"\n",
    "    oldbeta = np.randuom.uniform(size=nitem)\n",
    "    oldtheta = np.random.uniform(size=nsample)\n",
    "    oldz = np.random.uniform(size=(nsample, ndim))\n",
    "    oldw = np.random.uniform(size=(nitem, ndim))\n",
    "    \"\"\"\n",
    "    \n",
    "    oldbeta = randu(nitem)\n",
    "    oldtheta = randu(nsample)\n",
    "    oldz = randu(nsample, ndim)\n",
    "    oldw = randu(nitem, ndim)\n",
    "\n",
    "    # oldbeta = np.random.uniform(nitem)\n",
    "    # oldtheta = np.random.uniform(nsample)\n",
    "    # oldz = np.random.rand(nsample, ndim)\n",
    "    # oldw = np.random.rand(nitem, ndim)\n",
    "\n",
    "    oldbeta = oldbeta * 4.0 - 2.0\n",
    "    oldtheta = oldtheta * 4.0 - 2.0\n",
    "    oldz = oldz * 2.0 - 1.0\n",
    "    oldw = oldw * 2.0 - 1.0\n",
    "\n",
    "    newbeta = (oldbeta)\n",
    "    newtheta = (oldtheta)\n",
    "    newz = (oldz)\n",
    "    neww = (oldw)\n",
    "\n",
    "    ##############################################################################\n",
    "\n",
    "    oldgamma = 1\n",
    "    newgamma = 1  # gamma1 = log(gamma)\n",
    "\n",
    "    samp_beta = zeros((niter - nburn) // nthin, nitem)\n",
    "    samp_theta = zeros((niter - nburn) // nthin, nsample)\n",
    "\n",
    "    samp_z = zeros((niter - nburn) // nthin, nsample, ndim)\n",
    "    samp_w = zeros((niter - nburn) // nthin, nitem, ndim)\n",
    "\n",
    "    samp_sd_theta = zeros((niter - nburn) // nthin)\n",
    "    samp_sd = zeros((niter - nburn) // nthin)\n",
    "    samp_mle = zeros((niter - nburn) // nthin)\n",
    "    samp_gamma = zeros((niter - nburn) // nthin)\n",
    "\n",
    "    accept_beta = zeros(nitem)\n",
    "    accept_theta = zeros(nsample)\n",
    "    accept_z = zeros(nsample)\n",
    "    accept_w = zeros(nitem)\n",
    "\n",
    "    accept_gamma = 0\n",
    "    accept = 0\n",
    "    count = 0\n",
    "\n",
    "    dist = zeros(nsample, nitem)\n",
    "\n",
    "    old_dist_k = zeros(nitem)\n",
    "    new_dist_k = zeros(nitem)\n",
    "    old_dist_i = zeros(nsample)\n",
    "    new_dist_i = zeros(nsample)\n",
    "\n",
    "    ##############################################################################\n",
    "\n",
    "    for iter in range(niter):\n",
    "        # dist(j,i) is distance of z_j and w_i\n",
    "\n",
    "        dist.zeros()  # 매 이터레이션마다 거리 매트릭스를 0으로 리셋\n",
    "\n",
    "        for i in range(nitem):\n",
    "            for k in range(nsample):\n",
    "                dist_temp = 0.0\n",
    "                for j in range(ndim):\n",
    "                    dist_temp += pow((oldz[k, j] - oldw[i, j]), 2.0)\n",
    "                    dist[k, i] = sqrt(dist_temp)\n",
    "\n",
    "        # beta update\n",
    "        for i in range(nitem):\n",
    "            # TODO 컬럼부터 갱신하는 이유가 있는건가?\n",
    "\n",
    "            #newbeta[i] = np.random.normal(oldbeta[i], jump_beta, 1)\n",
    "            newbeta[i] = oldbeta[i] + jump_beta*randn()\n",
    "            \n",
    "            old_like_beta = 0.0\n",
    "            new_like_beta = 0.0\n",
    "\n",
    "            for k in range(nsample):\n",
    "                if data[k, i] != missing:\n",
    "                    new_like_beta += update_function(newbeta, oldtheta, oldgamma)\n",
    "                    old_like_beta += update_function(oldbeta, oldtheta, oldgamma)\n",
    "                    \n",
    "\n",
    "            #num = (new_like_beta +\n",
    "            #       scipy.stats.norm.logpdf(newbeta[i], pr_mean_beta, pr_sd_beta))\n",
    "            \n",
    "            num = (new_like_beta +\n",
    "                   log_normpdf(newbeta[i], pr_mean_beta, pr_sd_beta))\n",
    "            den = (old_like_beta +\n",
    "                   log_normpdf(oldbeta[i], pr_mean_beta, pr_sd_beta))\n",
    "            ratio = num - den\n",
    "\n",
    "            accept = rejection_algorithm(ratio)\n",
    "\n",
    "\n",
    "            if accept == 1:\n",
    "                oldbeta[i] = newbeta[i]\n",
    "                accept_beta[i] += 1.0 / (niter * 1.0)\n",
    "\n",
    "            else:\n",
    "                newbeta[i] = oldbeta[i]\n",
    "\n",
    "        # theta update\n",
    "        for k in range(nsample):\n",
    "            #newtheta[k] = np.random.normal(oldtheta[k], jump_theta, 1)\n",
    "            newtheta[k] = oldtheta[k] + jump_theta * randn()\n",
    "            \n",
    "            old_like_theta = 0.0\n",
    "            new_like_theta = 0.0\n",
    "\n",
    "            for i in range(nitem):\n",
    "                if data[k, i] != missing:\n",
    "                    new_like_theta += update_function(oldbeta, newtheta, oldgamma)\n",
    "                    old_like_theta += update_function(oldbeta, oldtheta, oldgamma)\n",
    "\n",
    "            num = (new_like_theta +\n",
    "                   log_normpdf(newtheta[k], pr_mean_theta, pr_sd_theta))\n",
    "            den = (old_like_theta +\n",
    "                   log_normpdf(oldtheta[k], pr_mean_theta, pr_sd_theta))\n",
    "            ratio = num - den\n",
    "\n",
    "            accept = rejection_algorithm(ratio)\n",
    "\n",
    "            if accept == 1:\n",
    "                oldtheta[k] = newtheta[k]\n",
    "                accept_theta[k] += 1.0 / (niter * 1.0)\n",
    "            else:\n",
    "                newtheta[k] = oldtheta[k]\n",
    "\n",
    "        # gamma(log(gamma)) update\n",
    "\n",
    "        #newgamma = np.random.lognormal(log(oldgamma), jump_gamma, 1)\n",
    "        \n",
    "        newgamma = exp(log(oldgamma) + jump_gamma*randn())\n",
    "        old_like_gamma = new_like_gamma = 0.0\n",
    "\n",
    "        for k in range(nsample):\n",
    "            for i in range(nitem):\n",
    "                if data[k, i] != missing:\n",
    "                    new_like_gamma += update_function(oldbeta, newtheta, newgamma)\n",
    "                    old_like_gamma += update_function(oldbeta, newtheta, oldgamma)\n",
    "\n",
    "        num = (new_like_gamma +\n",
    "               log_normpdf(log(oldgamma), log(newgamma), jump_gamma) + \n",
    "               log_normpdf(log(newgamma), pr_mean_gamma, pr_sd_gamma)\n",
    "               #scipy.stats.lognorm.logpdf(oldgamma, s=jump_gamma, loc=0, scale=exp(log(newgamma))) +\n",
    "               #scipy.stats.lognorm.logpdf(newgamma, s=pr_sd_gamma, loc=0, scale=exp(pr_mean_gamma))\n",
    "               )\n",
    "        den = (old_like_gamma +\n",
    "               log_normpdf(log(newgamma), log(oldgamma), jump_gamma) + \n",
    "               log_normpdf(log(oldgamma), pr_mean_gamma, pr_sd_gamma)\n",
    "               #scipy.stats.lognorm.logpdf(newgamma, s=jump_gamma, loc=0, scale=exp(log(oldgamma))) +\n",
    "               #scipy.stats.lognorm.logpdf(oldgamma, s=pr_sd_gamma, loc=0, scale=exp(pr_mean_gamma))\n",
    "               )\n",
    "        ratio = num - den\n",
    "\n",
    "        accept = rejection_algorithm(ratio)\n",
    "\n",
    "        if accept == 1:\n",
    "            oldgamma = newgamma\n",
    "            accept_gamma += 1.0 / (niter * 1.0)\n",
    "        else:\n",
    "            newgamma = oldgamma\n",
    "\n",
    "        # zj update\n",
    "\n",
    "        for k in range(nsample):\n",
    "            for j in range(ndim):\n",
    "                newz[k, j] = oldz[k, j] + jump_z*randn()\n",
    "            old_like_z = 0.0\n",
    "            new_like_z = 0.0\n",
    "\n",
    "            # calculate distance of oldw and newz\n",
    "\n",
    "            for i in range(nitem):\n",
    "                dist_old_temp = 0.0\n",
    "                dist_new_temp = 0.0\n",
    "                \n",
    "                for j in range(ndim):\n",
    "                    dist_new_temp += pow((newz[k, j] - oldw[i, j]), 2.0)\n",
    "                    dist_old_temp += pow((oldz[k, j] - oldw[i, j]), 2.0)\n",
    "                new_dist_k[i] = sqrt(dist_new_temp)\n",
    "                old_dist_k[i] = sqrt(dist_old_temp)\n",
    "\n",
    "            # calculate likelihood\n",
    "\n",
    "            for i in range(nitem):\n",
    "                if data[k, i] != missing:\n",
    "                    new_like_z += (- pow((data[k, i] - oldbeta[i] - oldtheta[k] + oldgamma * new_dist_k[i]), 2) /\n",
    "                                   (2 * pow(pr_sd, 2))\n",
    "                                   )\n",
    "                    old_like_z += (- pow((data[k, i] - oldbeta[i] - oldtheta[k] + oldgamma * old_dist_k[i]), 2) /\n",
    "                                   (2 * pow(pr_sd, 2))\n",
    "                                   )\n",
    "\n",
    "            num = den = 0.0\n",
    "\n",
    "            for j in range(ndim):\n",
    "                num += log_normpdf(newz[k, j], pr_mean_z, pr_sd_z)\n",
    "                #num += scipy.stats.norm.logpdf(newz[k, j], pr_mean_z, pr_sd_z)\n",
    "                den += log_normpdf(oldz[k, j], pr_mean_z, pr_sd_z)\n",
    "\n",
    "            # Rprintf(\"%.3f %.3f %.3f %.3f\\n\", num, den, new_like_z, old_like_z)\n",
    "            # arma::dvec newzz = dmvnorm(newz.cols(2*j,2*j+1),pr_mean_z,pr_cov_z,TRUE)\n",
    "            # arma::dvec oldzz = dmvnorm(oldz.cols(2*j,2*j+1),pr_mean_z,pr_cov_z,TRUE)\n",
    "\n",
    "            num += new_like_z\n",
    "            den += old_like_z\n",
    "            ratio = num - den\n",
    "\n",
    "            accept = rejection_algorithm(ratio)\n",
    "\n",
    "            if accept == 1:\n",
    "                for j in range(ndim):\n",
    "                    oldz[k, j] = newz[k, j]\n",
    "                accept_z[k] += 1.0 / (niter * 1.0)\n",
    "\n",
    "            else:\n",
    "                for j in range(ndim):\n",
    "                    newz[k, j] = oldz[k, j]\n",
    "\n",
    "        \n",
    "        \n",
    "        #  wi update\n",
    "        for i in range(nitem):\n",
    "            for j in range(ndim):\n",
    "                neww[i, j] = oldw[i, j] + jump_w*randn()\n",
    "                #neww[i, j] = np.random.normal(oldw[i, j], jump_w, 1)\n",
    "            old_like_w = 0.0\n",
    "            new_like_w = 0.0\n",
    "\n",
    "            # calculate distance of neww and oldz\n",
    "\n",
    "            for k in range(nsample):\n",
    "                dist_old_temp = 0.0\n",
    "                dist_new_temp = 0.0\n",
    "                \n",
    "                for j in range(ndim):\n",
    "                    dist_new_temp += pow((oldz[k, j] - neww[i, j]), 2.0)  # TODO: Why Old - New?\n",
    "                    dist_old_temp += pow((oldz[k, j] - oldw[i, j]), 2.0)\n",
    "                new_dist_i[k] = sqrt(dist_new_temp)\n",
    "                old_dist_i[k] = sqrt(dist_old_temp)\n",
    "\n",
    "            # calculate likelihood\n",
    "\n",
    "            for k in range(nsample):\n",
    "                if data[k, i] != missing:\n",
    "                    new_like_w += (- pow((data[k, i] - oldbeta[i] - oldtheta[k] + oldgamma * new_dist_i[k]), 2) /\n",
    "                                   (2 * pow(pr_sd, 2))\n",
    "                                   )\n",
    "                    old_like_w += (- pow((data[k, i] - oldbeta[i] - oldtheta[k] + oldgamma * old_dist_i[k]), 2) /\n",
    "                                   (2 * pow(pr_sd, 2))\n",
    "                                   )\n",
    "\n",
    "            num = den = 0.0\n",
    "\n",
    "            for j in range(ndim):\n",
    "                num += log_normpdf(neww[i, j], pr_mean_w, pr_sd_w)\n",
    "                #num += scipy.stats.norm.logpdf(neww[i, j], pr_mean_w, pr_sd_w)\n",
    "                den += log_normpdf(oldw[i, j], pr_mean_w, pr_sd_w)\n",
    "\n",
    "            num += new_like_w\n",
    "            den += old_like_w\n",
    "            ratio = num - den\n",
    "\n",
    "            accept = rejection_algorithm(ratio)\n",
    "\n",
    "            if accept == 1:\n",
    "                for j in range(ndim):\n",
    "                    oldw[i, j] = neww[i, j]\n",
    "                accept_w[i] += 1.0 / (niter * 1.0)\n",
    "            else:\n",
    "                for j in range(ndim):\n",
    "                    neww[i, j] = oldw[i, j]\n",
    "\n",
    "        # sigma_theta update with gibbs\n",
    "\n",
    "        \n",
    "        post_a_th_sigma = pr_a_th_sigma * 2 + nsample\n",
    "        post_b_th_sigma = pr_b_th_sigma\n",
    "\n",
    "        for j in range(nsample):  # TODO: 여기 j인데 nsample인거 맞음?\n",
    "            post_b_th_sigma += pow((oldtheta[j] - pr_mean_theta), 2.0)\n",
    "        pr_sd_theta = sqrt(2 * post_b_th_sigma * (1.0/chi2rnd(post_a_th_sigma)))\n",
    "                                                  #sum(square(randn(post_a_th_sigma//1)))))\n",
    "                                                  #np.random.chisquare(post_a_th_sigma)))\n",
    "                                                  \n",
    "                                                  \n",
    "        \n",
    "        \n",
    "\n",
    "        # dist(j,i) is distance of z_j and w_i\n",
    "\n",
    "        dist.zeros()\n",
    "\n",
    "        for i in range(nitem):\n",
    "            for k in range(nsample):\n",
    "                dist_temp = 0.0\n",
    "                for j in range(ndim):\n",
    "                    dist_temp += pow((oldz[k, j] - oldw[i, j]), 2.0)\n",
    "                dist[k, i] = sqrt(dist_temp)\n",
    "\n",
    "        # sigma update with gibbs\n",
    "\n",
    "        post_a_sigma = pr_a_sigma * 2 + nsample * nitem\n",
    "        post_b_sigma = pr_b_sigma\n",
    "\n",
    "        for j in range(nsample):  # TODO: 여기 j인데 nsample인거 맞음?\n",
    "            for i in range(nitem):\n",
    "                post_b_sigma += pow((data[j, i] - oldbeta[i] - oldtheta[j] + oldgamma * dist[j, i]), 2.0) / 2\n",
    "\n",
    "        pr_sd = sqrt(2 * post_b_sigma * (1.0/chi2rnd(post_a_th_sigma))) #post_a_th_sigma//\n",
    "        \n",
    "                                         #np.random.chisquare(post_a_sigma)))\n",
    "                                         \n",
    "                                         \n",
    "                                         \n",
    "                                         \n",
    "\n",
    "        # burn, thin\n",
    "\n",
    "        if iter >= nburn and iter % nthin == 0:\n",
    "            for i in range(nitem):\n",
    "                samp_beta[count, i] = oldbeta[i]\n",
    "            for k in range(nsample):\n",
    "                samp_theta[count, k] = oldtheta[k]\n",
    "            for i in range(nitem):\n",
    "                for j in range(ndim):\n",
    "                    samp_w[count, i, j] = oldw[i, j]\n",
    "            for k in range(nsample):\n",
    "                for j in range(ndim):\n",
    "                    samp_z[count, k, j] = oldz[k, j]\n",
    "\n",
    "            samp_gamma[count] = oldgamma\n",
    "            samp_sd_theta[count] = pr_sd_theta\n",
    "            samp_sd[count] = pr_sd\n",
    "\n",
    "            mle = 0.0\n",
    "\n",
    "            for i in range(nitem):\n",
    "                mle += log_normpdf(oldbeta[i], pr_mean_beta, pr_sd_beta)\n",
    "                #mle += scipy.stats.norm.logpdf(oldbeta[i], pr_mean_beta, pr_sd_beta)\n",
    "            for k in range(nsample):\n",
    "                mle += log_normpdf(oldtheta[k], pr_mean_theta, pr_sd_theta)\n",
    "            for i in range(nitem):\n",
    "                for j in range(ndim):\n",
    "                    mle += log_normpdf(oldw[i, j], pr_mean_w, pr_sd_w)\n",
    "            for k in range(nsample):\n",
    "                for j in range(ndim):\n",
    "                    mle += log_normpdf(oldz[k, j], pr_mean_z, pr_sd_z)\n",
    "            for k in range(nsample):\n",
    "                for i in range(nitem):\n",
    "                    mle += (- pow((data[k, i] - oldbeta[i] - oldtheta[k] + oldgamma * dist[k, i]), 2)\n",
    "                            / (2 * pow(pr_sd, 2)))\n",
    "\n",
    "            \n",
    "            mle += log_normpdf(log(oldgamma), pr_mean_gamma, pr_sd_gamma)\n",
    "            #mle += scipy.stats.lognorm.logpdf(oldgamma, s=pr_sd_gamma, loc=0, scale=exp(pr_mean_gamma))\n",
    "            samp_mle[count] = mle\n",
    "\n",
    "            count += 1\n",
    "\n",
    "        if iter % nprint == 0:\n",
    "            print(\"Iteration: \", iter)\n",
    "            print(\"count\", count)\n",
    "            for i in range(nitem):\n",
    "                print(\"nitem: \", i, \" with \", oldbeta[i])\n",
    "            print(\"oldgamma: \", oldgamma, \"     pr_sd_theta: \", pr_sd_theta)\n",
    "\n",
    "    return {\"beta\": samp_beta,\n",
    "            \"theta\": samp_theta,\n",
    "            \"z\": samp_z,\n",
    "            \"w\": samp_w,\n",
    "            \"gamma\": samp_gamma,\n",
    "            \"sigma_theta\": samp_sd_theta,\n",
    "            \"sigma\": samp_sd,\n",
    "            \"map\": samp_mle,\n",
    "            \"accept_beta\": accept_beta,\n",
    "            \"accept_theta\": accept_theta,\n",
    "            \"accept_z\": accept_z,\n",
    "            \"accept_w\": accept_w,\n",
    "            \"accept_gamma\": accept_gamma}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "eb5396c9-f521-4fc8-ad3f-3d34ffb05b19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pyarma.pyarma.mat object at 0000023703FE9840>\n",
       "[matrix size: 1x1]\n",
       "   2.4195"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bee64db-c2fd-4df7-adf3-c398b3858b76",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e12ab658-a26f-483e-be49-497bc4565219",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad83c7da-dbca-493c-b5a6-ae1ef36f45c9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc70c7c6-5aa4-4803-b604-31866600c555",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ad7914a-c8cc-48b5-9888-1b6f64b651f4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b24f3d5-56a7-4fea-b140-f68860fee4a8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d64695ca-1a08-4dae-a78c-f494c5688673",
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import *\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import scipy\n",
    "\n",
    "from math import *\n",
    "import numpy as np\n",
    "import scipy.stats\n",
    "\n",
    "from copy import *\n",
    "\n",
    "from sklearn import datasets\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0856d160-f953-4e6b-a2c4-1b0244e6bcf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('data_prob_90.csv', header=0, delim_whitespace=False)\n",
    "data_name = data.columns[1:]\n",
    "data = np.array(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "25d9e406-f006-4278-b50c-e2b7007596f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_word = pd.DataFrame(data[:, 0]) # 데이터 인풋. 인풋된 데이터는 data. input 되는 것은 논문 더미들.\n",
    "\n",
    "data = np.delete(data, 0, 1) # 0번째 column은 data_word. 뽑아내고 나머지 데이타 보존.\n",
    "\n",
    "data = np.nan_to_num(data, copy=True, nan=99) # na인 cell은 값을 99로 설정."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c04fa158-d124-4317-8803-31982d4b6b3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.array(data, dtype=float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7d25327b-b947-48ca-a3ac-3a05c37dd83d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_m = data # 데이터 타입 매트릭스로 바뀐 데이터. 파이썬에선 pd.dataframe 사용\n",
    "\n",
    "logit_x = np.log(data_m / (1 - data_m)) # 매트릭스 데이터를 logit化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b7df1361-e120-4256-b89b-c64759b555f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "data_m = MinMaxScaler().fit_transform(data_m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4e3e0acf-f8af-4209-bfa8-285b7e90e5d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "# <editor-fold desc=\"covid_20 parameters\">\n",
    "\n",
    "\"\"\"\n",
    "ndim     = 2 \n",
    "niter    = 55000\n",
    "nburn    = 5000\n",
    "nthin    = 5\n",
    "nprint   = 5000\n",
    "\"\"\"\n",
    "\n",
    "ndim = 2 #차원?\n",
    "niter = 200\n",
    "nburn = 0\n",
    "nthin = 5 #thining lapse\n",
    "nprint = 100\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "모든 topic의 분포는 theta ~ 디리클레 알파를 따름\n",
    "\n",
    "biterm 총체 B에서 biterm b를 뽑으면, 이 biterm이 어느 topic z에 속할지는 z ~ 다항분포 세타\n",
    "\n",
    "topic z의 topic-word 분포는 phi_z ~ 디리클레 베타를 따름\n",
    "topic = z, word = w. z가 정해졌을 때 이로부터 각 단어가 가지는 확률을 모아서 set으로 한것이 phi_z.\n",
    "\n",
    "골라진 topic에 대응하는 topic-word 분포로부터 단어 2개가 골라질 확률은 w_i, w_j ~ 다항(phi_z)를 따름\n",
    "\"\"\"\n",
    "\n",
    "jump_beta = 0.3\n",
    "jump_theta = 1.0\n",
    "jump_w = 0.06\n",
    "jump_z = 0.50\n",
    "jump_gamma = 0.01\n",
    "\n",
    "pr_mean_beta = 0\n",
    "pr_sd_beta = 1\n",
    "pr_mean_theta = 0\n",
    "pr_sd_theta = 1\n",
    "pr_mean_gamma = 0.0\n",
    "pr_sd_gamma = 1.0\n",
    "pr_a_sigma = 0.001\n",
    "pr_b_sigma = 0.001\n",
    "pr_a_th_sigma = 0.001\n",
    "pr_b_th_sigma = 0.001\n",
    "# </editor-fold> #TODO 뭐지? 패러미터 스태티스틱?\n",
    "#TODO 뭐지? 패러미터 스태티스틱?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "492288ca-aaf1-4cbe-aa50-1e0b07f13914",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a836e419-6284-462b-ad6d-d7a9c7708ea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = logit_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f43bb247-ecef-4d52-85b0-413043cb532d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from pyarma import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7f319489-7b64-4820-864e-43c621219b8d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "missing = 99"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "beecb613-1b36-422b-8d0f-8912afca5ed1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7908b2f7-e985-4267-b54f-a3456a6e15a9",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'post_a_th_sigma' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_29324/1657022074.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mpost_a_th_sigma\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'post_a_th_sigma' is not defined"
     ]
    }
   ],
   "source": [
    "post_a_th_sigma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "495c1907-292a-439f-b517-01a3593c4ec3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:  0\n",
      "count 1\n",
      "nitem:  0  with  -1.014847381525794\n",
      "nitem:  1  with  -1.2065598313876296\n",
      "nitem:  2  with  0.30897432558000626\n",
      "nitem:  3  with  -1.7232494559262002\n",
      "nitem:  4  with  -1.6222650365270164\n",
      "nitem:  5  with  0.40473846789246415\n",
      "nitem:  6  with  -0.015435949255703574\n",
      "nitem:  7  with  1.9703420061905978\n",
      "nitem:  8  with  1.3548053850468464\n",
      "nitem:  9  with  -0.7999437199286434\n",
      "nitem:  10  with  -0.13129407143117877\n",
      "nitem:  11  with  -1.7966029416158933\n",
      "nitem:  12  with  -1.0469756687001777\n",
      "nitem:  13  with  -0.9086248551558364\n",
      "nitem:  14  with  -1.01486204750209\n",
      "nitem:  15  with  -0.05113743969888285\n",
      "nitem:  16  with  -0.24274030342231928\n",
      "nitem:  17  with  -0.9637447595568059\n",
      "nitem:  18  with  1.681029374502445\n",
      "nitem:  19  with  1.1133749072635486\n",
      "oldgamma:  1.0071545306075054      pr_sd_theta:  2.154734404943964\n",
      "Iteration:  100\n",
      "count 21\n",
      "nitem:  0  with  -6.479237327723866\n",
      "nitem:  1  with  -0.37869916702831546\n",
      "nitem:  2  with  -0.9549865213994746\n",
      "nitem:  3  with  0.15515225348147205\n",
      "nitem:  4  with  -2.223843691233381\n",
      "nitem:  5  with  0.2373052444917949\n",
      "nitem:  6  with  3.390027238630508\n",
      "nitem:  7  with  0.03848067253297521\n",
      "nitem:  8  with  -2.3910665736201273\n",
      "nitem:  9  with  -6.349327811056303\n",
      "nitem:  10  with  -3.605282914504881\n",
      "nitem:  11  with  -0.5796303442084214\n",
      "nitem:  12  with  2.100436327843954\n",
      "nitem:  13  with  -2.752058742609866\n",
      "nitem:  14  with  -10.401790790336166\n",
      "nitem:  15  with  0.6779770082692386\n",
      "nitem:  16  with  -2.875598163099924\n",
      "nitem:  17  with  -7.891773606334253\n",
      "nitem:  18  with  -0.000594218519358064\n",
      "nitem:  19  with  1.1115579010258365\n",
      "oldgamma:  1.1641175521841642      pr_sd_theta:  13.82721393543006\n"
     ]
    }
   ],
   "source": [
    "logit_x = mat(logit_x)\n",
    "\n",
    "output = onepl_lsrm_cont_missing(logit_x,\n",
    "                                 ndim, niter, nburn, nthin, nprint,\n",
    "                                 jump_beta, jump_theta, jump_gamma, jump_z, jump_w,\n",
    "                                 pr_mean_beta, pr_sd_beta, pr_a_th_sigma, pr_b_th_sigma, pr_mean_theta,\n",
    "                                 pr_a_sigma, pr_b_sigma, pr_mean_gamma, pr_sd_gamma,\n",
    "                                 99)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c06648d2-6211-4993-ac01-c08c89ff49c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyarma import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "84aa367d-8a8d-4088-b5d3-ae77ba0a087a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'beta': <pyarma.pyarma.mat object at 000001E392E13490>\n",
       " [matrix size: 40x20]\n",
       "   -1.0148  -1.2066   0.3090   ...   1.1134\n",
       "   -0.8802  -1.7158   0.1287   ...   0.1731\n",
       "   -0.9720  -1.2216   1.0414   ...   0.5790\n",
       "         :        :        :   ...        :\n",
       "   -7.4135   0.0575   3.0558   ...   3.9777,\n",
       " 'theta': <pyarma.pyarma.mat object at 000001E392E13F20>\n",
       " [matrix size: 40x548]\n",
       "    -0.3600    0.4527   -1.7514   ...    0.1829\n",
       "    -3.7228    4.5572   -2.3890   ...   -4.1766\n",
       "    -5.4823    2.9234   -2.4197   ...   -3.7259\n",
       "          :         :         :   ...         :\n",
       "   -24.9023   16.3978   -8.4027   ...   -2.7940,\n",
       " 'z': <pyarma.pyarma.cube object at 000001E392E6DD70>\n",
       " [cube size: 40x548x2]\n",
       " [cube slice: 0]\n",
       "    0.5184  -0.0475  -1.0429   ...   0.7912\n",
       "    1.3544  -0.3214   0.6103   ...  -0.0589\n",
       "    0.5841   2.2018   0.5817   ...  -0.6557\n",
       "         :        :        :   ...        :\n",
       "    3.1964  -4.8537   5.1755   ...   6.8904\n",
       " \n",
       " [cube slice: 1]\n",
       "    1.3339  -0.7138  -1.0815   ...  -1.4446\n",
       "    0.1231  -0.3467  -1.3821   ...  -1.9265\n",
       "    0.8196   0.6359  -2.1070   ...  -2.5039\n",
       "         :        :        :   ...        :\n",
       "    6.9069   1.3492   6.5902   ...   2.8821,\n",
       " 'w': <pyarma.pyarma.cube object at 000001E392E6E7B0>\n",
       " [cube size: 40x20x2]\n",
       " [cube slice: 0]\n",
       "   -0.1290   0.0650   0.1702   ...   0.5917\n",
       "   -0.1303   0.1430   0.2082   ...   0.5047\n",
       "   -0.3792   0.0789  -0.0460   ...   0.3989\n",
       "         :        :        :   ...        :\n",
       "   -0.7578  -0.0969  -0.3503   ...  -0.3163\n",
       " \n",
       " [cube slice: 1]\n",
       "    0.8111  -0.7572  -0.3326   ...  -0.5038\n",
       "    1.1900  -0.7127  -0.2813   ...  -0.7452\n",
       "    1.1738  -1.0243  -0.2766   ...  -1.0239\n",
       "         :        :        :   ...        :\n",
       "    1.6507  -1.1297  -0.6454   ...  -1.0595,\n",
       " 'gamma': <pyarma.pyarma.mat object at 000001E392FAC150>\n",
       " [matrix size: 40x1]\n",
       "    1.0072\n",
       "    1.0189\n",
       "    1.0203\n",
       "         :        \n",
       "    1.0913,\n",
       " 'sigma_theta': <pyarma.pyarma.mat object at 000001E392FAC630>\n",
       " [matrix size: 40x1]\n",
       "     2.1547\n",
       "     3.6874\n",
       "     4.9520\n",
       "          :         \n",
       "    19.4477,\n",
       " 'sigma': <pyarma.pyarma.mat object at 000001E392FABFB0>\n",
       " [matrix size: 40x1]\n",
       "    56.3597\n",
       "    52.8088\n",
       "    55.1547\n",
       "          :         \n",
       "    72.1392,\n",
       " 'map': <pyarma.pyarma.mat object at 000001E392FAB040>\n",
       " [matrix size: 40x1]\n",
       "   -2.8067e+03\n",
       "   -4.7812e+03\n",
       "   -7.1518e+03\n",
       "             :            \n",
       "   -8.5190e+04,\n",
       " 'accept_beta': <pyarma.pyarma.mat object at 000001E392FAB450>\n",
       " [matrix size: 20x1]\n",
       "    1.0000\n",
       "    1.0000\n",
       "    1.0000\n",
       "         :        \n",
       "    1.0000,\n",
       " 'accept_theta': <pyarma.pyarma.mat object at 000001E392FAC8A0>\n",
       " [matrix size: 548x1]\n",
       "    1.0000\n",
       "    1.0000\n",
       "    1.0000\n",
       "         :        \n",
       "    1.0000,\n",
       " 'accept_z': <pyarma.pyarma.mat object at 000001E392FAB860>\n",
       " [matrix size: 548x1]\n",
       "    1.0000\n",
       "    1.0000\n",
       "    1.0000\n",
       "         :        \n",
       "    1.0000,\n",
       " 'accept_w': <pyarma.pyarma.mat object at 000001E392FAC2F0>\n",
       " [matrix size: 20x1]\n",
       "    1.0000\n",
       "    1.0000\n",
       "    1.0000\n",
       "         :        \n",
       "    1.0000,\n",
       " 'accept_gamma': 0.8300000000000006}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
