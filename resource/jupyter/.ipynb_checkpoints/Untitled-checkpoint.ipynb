{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c4d9f30b-1ad8-49ea-8a21-93095a16b457",
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import *\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import scipy\n",
    "\n",
    "from math import *\n",
    "import numpy as np\n",
    "import scipy.stats\n",
    "\n",
    "from copy import *\n",
    "\n",
    "from sklearn import datasets\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "445a2e65-df72-44ee-b6a5-f6139df03da4",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('data_prob_90.csv', header=0, delim_whitespace=False)\n",
    "data_name = data.columns[1:]\n",
    "data = np.array(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9272f3cf-cee9-4a33-a5be-3a2bcd25cd64",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_word = pd.DataFrame(data[:, 0]) # 데이터 인풋. 인풋된 데이터는 data. input 되는 것은 논문 더미들.\n",
    "\n",
    "data = np.delete(data, 0, 1) # 0번째 column은 data_word. 뽑아내고 나머지 데이타 보존.\n",
    "\n",
    "data = np.nan_to_num(data, copy=True, nan=99) # na인 cell은 값을 99로 설정."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "218b9f36-b465-4c55-b1c0-66f0a0428b07",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.array(data, dtype=float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "48cc5a4a-15a5-4f0e-8e31-b5f3c0c2edc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_m = data # 데이터 타입 매트릭스로 바뀐 데이터. 파이썬에선 pd.dataframe 사용\n",
    "\n",
    "logit_x = np.log(data_m / (1 - data_m)) # 매트릭스 데이터를 logit化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "784ba360-2716-4bf0-8197-21131a94425f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "data_m = MinMaxScaler().fit_transform(data_m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dbd0c021-4d00-4657-ab16-342df50a0438",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "# <editor-fold desc=\"covid_20 parameters\">\n",
    "\n",
    "\n",
    "ndim     = 2 \n",
    "niter    = 55000\n",
    "nburn    = 5000\n",
    "nthin    = 5\n",
    "nprint   = 5000\n",
    "\"\"\"\n",
    "\n",
    "ndim = 2 #차원?\n",
    "niter = 200\n",
    "nburn = 0\n",
    "nthin = 5 #thining lapse\n",
    "nprint = 100\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "모든 topic의 분포는 theta ~ 디리클레 알파를 따름\n",
    "\n",
    "biterm 총체 B에서 biterm b를 뽑으면, 이 biterm이 어느 topic z에 속할지는 z ~ 다항분포 세타\n",
    "\n",
    "topic z의 topic-word 분포는 phi_z ~ 디리클레 베타를 따름\n",
    "topic = z, word = w. z가 정해졌을 때 이로부터 각 단어가 가지는 확률을 모아서 set으로 한것이 phi_z.\n",
    "\n",
    "골라진 topic에 대응하는 topic-word 분포로부터 단어 2개가 골라질 확률은 w_i, w_j ~ 다항(phi_z)를 따름\n",
    "\"\"\"\n",
    "\n",
    "jump_beta = 0.3\n",
    "jump_theta = 1.0\n",
    "jump_w = 0.06\n",
    "jump_z = 0.50\n",
    "jump_gamma = 0.01\n",
    "\n",
    "pr_mean_beta = 0\n",
    "pr_sd_beta = 1\n",
    "pr_mean_theta = 0\n",
    "pr_sd_theta = 1\n",
    "pr_mean_gamma = 0.0\n",
    "pr_sd_gamma = 1.0\n",
    "pr_a_sigma = 0.001\n",
    "pr_b_sigma = 0.001\n",
    "pr_a_th_sigma = 0.001\n",
    "pr_b_th_sigma = 0.001\n",
    "# </editor-fold> #TODO 뭐지? 패러미터 스태티스틱?\n",
    "#TODO 뭐지? 패러미터 스태티스틱?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47478973-d6c9-4f0d-ae1e-2537026fb2d6",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ca29d0e7-9858-47bf-a9b4-5465f9e9449a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = logit_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "66a08be6-86bb-4a8d-94d4-ae9ec279f2c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from pyarma import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "754fde9a-d9c9-4aeb-8d28-367d9ac51257",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "missing = 99"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "13e777f1-9be6-4096-aa25-ac06690d3569",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def onepl_lsrm_cont_missing(data,\n",
    "\n",
    "                            ndim,\n",
    "                            niter,\n",
    "                            nburn,\n",
    "                            nthin,\n",
    "                            nprint,\n",
    "\n",
    "                            jump_beta,\n",
    "                            jump_theta,\n",
    "                            jump_gamma,\n",
    "                            jump_z,\n",
    "                            jump_w,\n",
    "\n",
    "                            pr_mean_beta,\n",
    "                            pr_sd_beta,\n",
    "                            pr_a_th_sigma,\n",
    "                            pr_b_th_sigma,\n",
    "                            pr_mean_theta,\n",
    "\n",
    "                            pr_a_sigma,\n",
    "                            pr_b_sigma,\n",
    "                            pr_mean_gamma,\n",
    "                            pr_sd_gamma,\n",
    "\n",
    "                            missing):\n",
    "    ##############################################################################\n",
    "\n",
    "    def update_function(beta, theta, gamma):\n",
    "        return (- pow((data[k, i] - beta[i] - theta[k] + gamma * dist[k, i]), 2) /\n",
    "                (2 * pow(pr_sd, 2))\n",
    "                )\n",
    "\n",
    "    def rejection_algorithm(ratio):\n",
    "        if ratio > 0.0:\n",
    "            accept = 1\n",
    "        else:\n",
    "            un = np.random.uniform(1)\n",
    "            if np.log(un) < ratio:\n",
    "                accept = 1\n",
    "            else:\n",
    "                accept = 0\n",
    "\n",
    "        return accept\n",
    "\n",
    "    ##############################################################################\n",
    "\n",
    "    nsample = data.shape[0]\n",
    "    nitem = data.shape[1]\n",
    "\n",
    "    pr_mean_z = 0.0\n",
    "    pr_mean_w = 0.0\n",
    "\n",
    "    pr_sd_z = 1.0\n",
    "    pr_sd_w = 1.0\n",
    "    pr_sd = 1.0\n",
    "    pr_sd_theta = 1.0\n",
    "\n",
    "    oldbeta = np.random.uniform(size=nitem)\n",
    "    oldtheta = np.random.uniform(size=nsample)\n",
    "    oldz = np.random.uniform(size=(nsample, ndim))\n",
    "    oldw = np.random.uniform(size=(nitem, ndim))\n",
    "\n",
    "    # oldbeta = np.random.uniform(nitem)\n",
    "    # oldtheta = np.random.uniform(nsample)\n",
    "    # oldz = np.random.rand(nsample, ndim)\n",
    "    # oldw = np.random.rand(nitem, ndim)\n",
    "\n",
    "    oldbeta = oldbeta * 4.0 - 2.0\n",
    "    oldtheta = oldtheta * 4.0 - 2.0\n",
    "    oldz = oldz * 2.0 - 1.0\n",
    "    oldw = oldw * 2.0 - 1.0\n",
    "\n",
    "    newbeta = deepcopy(oldbeta)\n",
    "    newtheta = deepcopy(oldtheta)\n",
    "    newz = deepcopy(oldz)\n",
    "    neww = deepcopy(oldw)\n",
    "\n",
    "    ##############################################################################\n",
    "\n",
    "    oldgamma = newgamma = 1  # gamma1 = log(gamma)\n",
    "\n",
    "    samp_beta = np.zeros(shape=((niter - nburn) // nthin, nitem))\n",
    "    samp_theta = np.zeros(shape=((niter - nburn) // nthin, nsample))\n",
    "\n",
    "    samp_z = np.zeros(shape=((niter - nburn) // nthin, nsample, ndim))\n",
    "    samp_w = np.zeros(shape=((niter - nburn) // nthin, nitem, ndim))\n",
    "\n",
    "    samp_sd_theta = np.zeros(shape=(niter - nburn) // nthin, )\n",
    "    samp_sd = np.zeros(shape=(niter - nburn) // nthin, )\n",
    "    samp_mle = np.zeros(shape=(niter - nburn) // nthin, )\n",
    "    samp_gamma = np.zeros(shape=(niter - nburn) // nthin, )\n",
    "\n",
    "    accept_beta = np.zeros(shape=nitem, )\n",
    "    accept_theta = np.zeros(shape=nsample, )\n",
    "    accept_z = np.zeros(shape=nsample, )\n",
    "    accept_w = np.zeros(shape=nitem, )\n",
    "\n",
    "    accept_gamma = 0\n",
    "    accept = 0\n",
    "    count = 0\n",
    "\n",
    "    dist = np.zeros(shape=(nsample, nitem), )\n",
    "\n",
    "    old_dist_k = np.zeros(nitem, )\n",
    "    new_dist_k = np.zeros(nitem, )\n",
    "    old_dist_i = np.zeros(nsample, )\n",
    "    new_dist_i = np.zeros(nsample, )\n",
    "\n",
    "    ##############################################################################\n",
    "\n",
    "\n",
    "    for iter in range(niter):\n",
    "        # dist(j,i) is distance of z_j and w_i\n",
    "\n",
    "        dist = np.where(True, 0, dist)  # 매 이터레이션마다 거리 매트릭스를 0으로 리셋\n",
    "\n",
    "        for i in range(nitem):\n",
    "            for k in range(nsample):\n",
    "                dist_temp = 0.0\n",
    "                for j in range(ndim):\n",
    "                    dist_temp += pow((oldz[k, j] - oldw[i, j]), 2.0)\n",
    "                    dist[k, i] = sqrt(dist_temp)\n",
    "\n",
    "        # beta update\n",
    "        for i in range(nitem):\n",
    "            # TODO 컬럼부터 갱신하는 이유가 있는건가?\n",
    "\n",
    "            newbeta[i] = np.random.normal(oldbeta[i], jump_beta, 1)\n",
    "            old_like_beta = new_like_beta = 0.0\n",
    "\n",
    "            for k in range(nsample):\n",
    "                if data[k, i] != missing:\n",
    "                    new_like_beta += update_function(newbeta, oldtheta, oldgamma)\n",
    "                    old_like_beta += update_function(oldbeta, oldtheta, oldgamma)\n",
    "                    \n",
    "\n",
    "            num = (new_like_beta +\n",
    "                   scipy.stats.norm.logpdf(newbeta[i], pr_mean_beta, pr_sd_beta))\n",
    "            den = (old_like_beta +\n",
    "                   scipy.stats.norm.logpdf(oldbeta[i], pr_mean_beta, pr_sd_beta))\n",
    "            ratio = num - den\n",
    "\n",
    "            accept = rejection_algorithm(ratio)\n",
    "\n",
    "\n",
    "            if accept == 1:\n",
    "                oldbeta[i] = newbeta[i]\n",
    "                accept_beta[i] += 1.0 / (niter * 1.0)\n",
    "\n",
    "            else:\n",
    "                newbeta[i] = oldbeta[i]\n",
    "\n",
    "        # theta update\n",
    "        for k in range(nsample):\n",
    "            newtheta[k] = np.random.normal(oldtheta[k], jump_theta, 1)\n",
    "            old_like_theta = new_like_theta = 0.0\n",
    "\n",
    "            for i in range(nitem):\n",
    "                if data[k, i] != missing:\n",
    "                    new_like_theta += update_function(oldbeta, newtheta, oldgamma)\n",
    "                    old_like_theta += update_function(oldbeta, oldtheta, oldgamma)\n",
    "\n",
    "            num = (new_like_theta +\n",
    "                   scipy.stats.norm.logpdf(newtheta[k], pr_mean_theta, pr_sd_theta))\n",
    "            den = (old_like_theta +\n",
    "                   scipy.stats.norm.logpdf(oldtheta[k], pr_mean_theta, pr_sd_theta))\n",
    "            ratio = num - den\n",
    "\n",
    "            accept = rejection_algorithm(ratio)\n",
    "\n",
    "            if accept == 1:\n",
    "                oldtheta[k] = newtheta[k]\n",
    "                accept_theta[k] += 1.0 / (niter * 1.0)\n",
    "            else:\n",
    "                newtheta[k] = oldtheta[k]\n",
    "\n",
    "        # gamma(log(gamma)) update\n",
    "\n",
    "        newgamma = np.random.lognormal(log(oldgamma), jump_gamma, 1)\n",
    "        old_like_gamma = new_like_gamma = 0.0\n",
    "\n",
    "        for k in range(nsample):\n",
    "            for i in range(nitem):\n",
    "                if data[k, i] != missing:\n",
    "                    new_like_gamma += update_function(oldbeta, newtheta, newgamma)\n",
    "                    old_like_gamma += update_function(oldbeta, newtheta, oldgamma)\n",
    "\n",
    "        num = (new_like_gamma +\n",
    "               scipy.stats.lognorm.logpdf(oldgamma, s=jump_gamma, loc=0, scale=exp(log(newgamma))) +\n",
    "               scipy.stats.lognorm.logpdf(newgamma, s=pr_sd_gamma, loc=0, scale=exp(pr_mean_gamma))\n",
    "               )\n",
    "        den = (old_like_gamma +\n",
    "               scipy.stats.lognorm.logpdf(newgamma, s=jump_gamma, loc=0, scale=exp(log(oldgamma))) +\n",
    "               scipy.stats.lognorm.logpdf(oldgamma, s=pr_sd_gamma, loc=0, scale=exp(pr_mean_gamma))\n",
    "               )\n",
    "        ratio = num - den\n",
    "\n",
    "        accept = rejection_algorithm(ratio)\n",
    "\n",
    "        if accept == 1:\n",
    "            oldgamma = newgamma\n",
    "            accept_gamma += 1.0 / (niter * 1.0)\n",
    "        else:\n",
    "            newgamma = oldgamma\n",
    "\n",
    "        # zj update\n",
    "\n",
    "        for k in range(nsample):\n",
    "            for j in range(ndim):\n",
    "                newz[k, j] = np.random.normal(oldz[k, j], jump_z, 1)\n",
    "            old_like_z = new_like_z = 0.0\n",
    "\n",
    "            # calculate distance of oldw and newz\n",
    "\n",
    "            for i in range(nitem):\n",
    "                dist_old_temp = dist_new_temp = 0.0\n",
    "                for j in range(ndim):\n",
    "                    dist_new_temp += pow((newz[k, j] - oldw[i, j]), 2.0)\n",
    "                    dist_old_temp += pow((oldz[k, j] - oldw[i, j]), 2.0)\n",
    "                new_dist_k[i] = sqrt(dist_new_temp)\n",
    "                old_dist_k[i] = sqrt(dist_old_temp)\n",
    "\n",
    "            # calculate likelihood\n",
    "\n",
    "            for i in range(nitem):\n",
    "                if data[k, i] != missing:\n",
    "                    new_like_z += (- pow((data[k, i] - oldbeta[i] - oldtheta[k] + oldgamma * new_dist_k[i]), 2) /\n",
    "                                   (2 * pow(pr_sd, 2))\n",
    "                                   )\n",
    "                    old_like_z += (- pow((data[k, i] - oldbeta[i] - oldtheta[k] + oldgamma * old_dist_k[i]), 2) /\n",
    "                                   (2 * pow(pr_sd, 2))\n",
    "                                   )\n",
    "\n",
    "            num = den = 0.0\n",
    "\n",
    "            for j in range(ndim):\n",
    "                num += scipy.stats.norm.logpdf(newz[k, j], pr_mean_z, pr_sd_z)\n",
    "                den += scipy.stats.norm.logpdf(oldz[k, j], pr_mean_z, pr_sd_z)\n",
    "\n",
    "            # Rprintf(\"%.3f %.3f %.3f %.3f\\n\", num, den, new_like_z, old_like_z)\n",
    "            # arma::dvec newzz = dmvnorm(newz.cols(2*j,2*j+1),pr_mean_z,pr_cov_z,TRUE)\n",
    "            # arma::dvec oldzz = dmvnorm(oldz.cols(2*j,2*j+1),pr_mean_z,pr_cov_z,TRUE)\n",
    "\n",
    "            num += new_like_z\n",
    "            den += old_like_z\n",
    "            ratio = num - den\n",
    "\n",
    "            accept = rejection_algorithm(ratio)\n",
    "\n",
    "            if accept == 1:\n",
    "                for j in range(ndim):\n",
    "                    oldz[k, j] = newz[k, j]\n",
    "                accept_z[k] += 1.0 / (niter * 1.0)\n",
    "\n",
    "            else:\n",
    "                for j in range(ndim):\n",
    "                    newz[k, j] = oldz[k, j]\n",
    "\n",
    "                #  wi update\n",
    "        for i in range(nitem):\n",
    "            for j in range(ndim):\n",
    "                neww[i, j] = np.random.normal(oldw[i, j], jump_w, 1)\n",
    "            old_like_w = new_like_w = 0.0\n",
    "\n",
    "            # calculate distance of neww and oldz\n",
    "\n",
    "            for k in range(nsample):\n",
    "                dist_old_temp = dist_new_temp = 0.0\n",
    "                for j in range(ndim):\n",
    "                    dist_new_temp += pow((oldz[k, j] - neww[i, j]), 2.0)  # TODO: Why Old - New?\n",
    "                    dist_old_temp += pow((oldz[k, j] - oldw[i, j]), 2.0)\n",
    "                new_dist_i[k] = sqrt(dist_new_temp)\n",
    "                old_dist_i[k] = sqrt(dist_old_temp)\n",
    "\n",
    "            # calculate likelihood\n",
    "\n",
    "            for k in range(nsample):\n",
    "                if data[k, i] != missing:\n",
    "                    new_like_w += (- pow((data[k, i] - oldbeta[i] - oldtheta[k] + oldgamma * new_dist_i[k]), 2) /\n",
    "                                   (2 * pow(pr_sd, 2))\n",
    "                                   )\n",
    "                    old_like_w += (- pow((data[k, i] - oldbeta[i] - oldtheta[k] + oldgamma * old_dist_i[k]), 2) /\n",
    "                                   (2 * pow(pr_sd, 2))\n",
    "                                   )\n",
    "\n",
    "            num = den = 0.0\n",
    "\n",
    "            for j in range(ndim):\n",
    "                num += scipy.stats.norm.logpdf(neww[i, j], pr_mean_w, pr_sd_w)\n",
    "                den += scipy.stats.norm.logpdf(oldw[i, j], pr_mean_w, pr_sd_w)\n",
    "\n",
    "            num += new_like_w\n",
    "            den += old_like_w\n",
    "            ratio = num - den\n",
    "\n",
    "            accept = rejection_algorithm(ratio)\n",
    "\n",
    "            if accept == 1:\n",
    "                for j in range(ndim):\n",
    "                    oldw[i, j] = neww[i, j]\n",
    "                accept_w[i] += 1.0 / (niter * 1.0)\n",
    "            else:\n",
    "                for j in range(ndim):\n",
    "                    neww[i, j] = oldw[i, j]\n",
    "\n",
    "        # sigma_theta update with gibbs\n",
    "\n",
    "        post_a_th_sigma = pr_a_th_sigma * 2 + nsample\n",
    "        post_b_th_sigma = pr_b_th_sigma\n",
    "\n",
    "        for j in range(nsample):  # TODO: 여기 j인데 nsample인거 맞음?\n",
    "            post_b_th_sigma += pow((oldtheta[j] - pr_mean_theta), 2.0)\n",
    "        pr_sd_theta = sqrt(2 * post_b_th_sigma * (1.0 / np.random.chisquare(post_a_th_sigma)))\n",
    "\n",
    "        # dist(j,i) is distance of z_j and w_i\n",
    "\n",
    "        dist = np.where(True, 0, dist)\n",
    "\n",
    "        for i in range(nitem):\n",
    "            for k in range(nsample):\n",
    "                dist_temp = 0.0\n",
    "                for j in range(ndim):\n",
    "                    dist_temp += pow((oldz[k, j] - oldw[i, j]), 2.0)\n",
    "                dist[k, i] = sqrt(dist_temp)\n",
    "\n",
    "        # sigma update with gibbs\n",
    "\n",
    "        post_a_sigma = pr_a_sigma * 2 + nsample * nitem\n",
    "        post_b_sigma = pr_b_sigma\n",
    "\n",
    "        for j in range(nsample):  # TODO: 여기 j인데 nsample인거 맞음?\n",
    "            for i in range(nitem):\n",
    "                post_b_sigma += pow((data[j, i] - oldbeta[i] - oldtheta[j] + oldgamma * dist[j, i]), 2.0) / 2\n",
    "\n",
    "        pr_sd = sqrt(2 * post_b_sigma * (1.0 / np.random.chisquare(post_a_sigma)))\n",
    "\n",
    "        # burn, thin\n",
    "\n",
    "        if iter >= nburn and iter % nthin == 0:\n",
    "            for i in range(nitem):\n",
    "                samp_beta[count, i] = oldbeta[i]\n",
    "            for k in range(nsample):\n",
    "                samp_theta[count, k] = oldtheta[k]\n",
    "            for i in range(nitem):\n",
    "                for j in range(ndim):\n",
    "                    samp_w[count, i, j] = oldw[i, j]\n",
    "            for k in range(nsample):\n",
    "                for j in range(ndim):\n",
    "                    samp_z[count, k, j] = oldz[k, j]\n",
    "\n",
    "            samp_gamma[count] = oldgamma\n",
    "            samp_sd_theta[count] = pr_sd_theta\n",
    "            samp_sd[count] = pr_sd\n",
    "\n",
    "            mle = 0.0\n",
    "\n",
    "            for i in range(nitem):\n",
    "                mle += scipy.stats.norm.logpdf(oldbeta[i], pr_mean_beta, pr_sd_beta)\n",
    "            for k in range(nsample):\n",
    "                mle += scipy.stats.norm.logpdf(oldtheta[k], pr_mean_theta, pr_sd_theta)\n",
    "            for i in range(nitem):\n",
    "                for j in range(ndim):\n",
    "                    mle += scipy.stats.norm.logpdf(oldw[i, j], pr_mean_w, pr_sd_w)\n",
    "            for k in range(nsample):\n",
    "                for j in range(ndim):\n",
    "                    mle += scipy.stats.norm.logpdf(oldz[k, j], pr_mean_z, pr_sd_z)\n",
    "            for k in range(nsample):\n",
    "                for i in range(nitem):\n",
    "                    mle += (- pow((data[k, i] - oldbeta[i] - oldtheta[k] + oldgamma * dist[k, i]), 2)\n",
    "                            / (2 * pow(pr_sd, 2)))\n",
    "\n",
    "            mle += scipy.stats.lognorm.logpdf(oldgamma, s=pr_sd_gamma, loc=0, scale=exp(pr_mean_gamma))\n",
    "            samp_mle[count] = mle\n",
    "\n",
    "            count += 1\n",
    "\n",
    "        if iter % nprint == 0:\n",
    "            print(\"Iteration: \", iter)\n",
    "            print(\"count\", count)\n",
    "            for i in range(nitem):\n",
    "                print(\"nitem: \", i, \" with \", oldbeta[i])\n",
    "            print(\"oldgamma: \", oldgamma, \"     pr_sd_theta: \", pr_sd_theta)\n",
    "\n",
    "    return {\"beta\": samp_beta,\n",
    "            \"theta\": samp_theta,\n",
    "            \"z\": samp_z,\n",
    "            \"w\": samp_w,\n",
    "            \"gamma\": samp_gamma,\n",
    "            \"sigma_theta\": samp_sd_theta,\n",
    "            \"sigma\": samp_sd,\n",
    "            \"map\": samp_mle,\n",
    "            \"accept_beta\": accept_beta,\n",
    "            \"accept_theta\": accept_theta,\n",
    "            \"accept_z\": accept_z,\n",
    "            \"accept_w\": accept_w,\n",
    "            \"accept_gamma\": accept_gamma}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3913fab9-567b-4a8d-b790-2e9d1d87787d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:  0\n",
      "count 0\n",
      "nitem:  0  with  -1.9350401497374379\n",
      "nitem:  1  with  1.5926341500302954\n",
      "nitem:  2  with  1.0876471041621665\n",
      "nitem:  3  with  -1.3360421796903652\n",
      "nitem:  4  with  -1.8160679511004845\n",
      "nitem:  5  with  -0.618587035011775\n",
      "nitem:  6  with  -1.2030359507377462\n",
      "nitem:  7  with  1.6567079581086346\n",
      "nitem:  8  with  -1.7436899532005499\n",
      "nitem:  9  with  -0.7468769587051729\n",
      "nitem:  10  with  0.811541856307731\n",
      "nitem:  11  with  0.1285121348927668\n",
      "nitem:  12  with  -1.0871706981520526\n",
      "nitem:  13  with  0.9603859975603259\n",
      "nitem:  14  with  -1.7116348984500118\n",
      "nitem:  15  with  1.0270767107772931\n",
      "nitem:  16  with  -1.2699154586126271\n",
      "nitem:  17  with  1.0489221635421644\n",
      "nitem:  18  with  0.5596435838347165\n",
      "nitem:  19  with  1.4566440338816675\n",
      "oldgamma:  [1.01191415]      pr_sd_theta:  2.000410829259988\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n",
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Song1\\anaconda3\\envs\\covid\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3441, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"C:\\Users\\Song1\\AppData\\Local\\Temp/ipykernel_16976/4274860929.py\", line 11, in <module>\n",
      "    output = onepl_lsrm_cont_missing(logit_x,\n",
      "  File \"C:\\Users\\Song1\\AppData\\Local\\Temp/ipykernel_16976/2650868760.py\", line 211, in onepl_lsrm_cont_missing\n",
      "    newz[k, j] = np.random.normal(oldz[k, j], jump_z, 1)\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Song1\\anaconda3\\envs\\covid\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2061, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Song1\\anaconda3\\envs\\covid\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1101, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"C:\\Users\\Song1\\anaconda3\\envs\\covid\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 248, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"C:\\Users\\Song1\\anaconda3\\envs\\covid\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 281, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"C:\\Users\\Song1\\anaconda3\\envs\\covid\\lib\\inspect.py\", line 1541, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"C:\\Users\\Song1\\anaconda3\\envs\\covid\\lib\\inspect.py\", line 1499, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"C:\\Users\\Song1\\anaconda3\\envs\\covid\\lib\\inspect.py\", line 709, in getsourcefile\n",
      "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
      "  File \"C:\\Users\\Song1\\anaconda3\\envs\\covid\\lib\\inspect.py\", line 755, in getmodule\n",
      "    os.path.realpath(f)] = module.__name__\n",
      "  File \"C:\\Users\\Song1\\anaconda3\\envs\\covid\\lib\\ntpath.py\", line 647, in realpath\n",
      "    path = _getfinalpathname(path)\n",
      "KeyboardInterrupt\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Song1\\anaconda3\\envs\\covid\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3441, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"C:\\Users\\Song1\\AppData\\Local\\Temp/ipykernel_16976/4274860929.py\", line 11, in <module>\n",
      "    output = onepl_lsrm_cont_missing(logit_x,\n",
      "  File \"C:\\Users\\Song1\\AppData\\Local\\Temp/ipykernel_16976/2650868760.py\", line 211, in onepl_lsrm_cont_missing\n",
      "    newz[k, j] = np.random.normal(oldz[k, j], jump_z, 1)\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Song1\\anaconda3\\envs\\covid\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2061, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Song1\\anaconda3\\envs\\covid\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3361, in run_ast_nodes\n",
      "    if (await self.run_code(code, result,  async_=asy)):\n",
      "  File \"C:\\Users\\Song1\\anaconda3\\envs\\covid\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3458, in run_code\n",
      "    self.showtraceback(running_compiled_code=True)\n",
      "  File \"C:\\Users\\Song1\\anaconda3\\envs\\covid\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2063, in showtraceback\n",
      "    stb = self.InteractiveTB.structured_traceback(etype,\n",
      "  File \"C:\\Users\\Song1\\anaconda3\\envs\\covid\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1367, in structured_traceback\n",
      "    return FormattedTB.structured_traceback(\n",
      "  File \"C:\\Users\\Song1\\anaconda3\\envs\\covid\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1267, in structured_traceback\n",
      "    return VerboseTB.structured_traceback(\n",
      "  File \"C:\\Users\\Song1\\anaconda3\\envs\\covid\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1124, in structured_traceback\n",
      "    formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n",
      "  File \"C:\\Users\\Song1\\anaconda3\\envs\\covid\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1082, in format_exception_as_a_whole\n",
      "    last_unique, recursion_repeat = find_recursion(orig_etype, evalue, records)\n",
      "  File \"C:\\Users\\Song1\\anaconda3\\envs\\covid\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 382, in find_recursion\n",
      "    return len(records), 0\n",
      "TypeError: object of type 'NoneType' has no len()\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Song1\\anaconda3\\envs\\covid\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2061, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'TypeError' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Song1\\anaconda3\\envs\\covid\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1101, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"C:\\Users\\Song1\\anaconda3\\envs\\covid\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 248, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"C:\\Users\\Song1\\anaconda3\\envs\\covid\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 281, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"C:\\Users\\Song1\\anaconda3\\envs\\covid\\lib\\inspect.py\", line 1541, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"C:\\Users\\Song1\\anaconda3\\envs\\covid\\lib\\inspect.py\", line 1499, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"C:\\Users\\Song1\\anaconda3\\envs\\covid\\lib\\inspect.py\", line 709, in getsourcefile\n",
      "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
      "  File \"C:\\Users\\Song1\\anaconda3\\envs\\covid\\lib\\inspect.py\", line 755, in getmodule\n",
      "    os.path.realpath(f)] = module.__name__\n",
      "  File \"C:\\Users\\Song1\\anaconda3\\envs\\covid\\lib\\ntpath.py\", line 647, in realpath\n",
      "    path = _getfinalpathname(path)\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Song1\\anaconda3\\envs\\covid\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3441, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"C:\\Users\\Song1\\AppData\\Local\\Temp/ipykernel_16976/4274860929.py\", line 11, in <module>\n",
      "    output = onepl_lsrm_cont_missing(logit_x,\n",
      "  File \"C:\\Users\\Song1\\AppData\\Local\\Temp/ipykernel_16976/2650868760.py\", line 211, in onepl_lsrm_cont_missing\n",
      "    newz[k, j] = np.random.normal(oldz[k, j], jump_z, 1)\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Song1\\anaconda3\\envs\\covid\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2061, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Song1\\anaconda3\\envs\\covid\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3361, in run_ast_nodes\n",
      "    if (await self.run_code(code, result,  async_=asy)):\n",
      "  File \"C:\\Users\\Song1\\anaconda3\\envs\\covid\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3458, in run_code\n",
      "    self.showtraceback(running_compiled_code=True)\n",
      "  File \"C:\\Users\\Song1\\anaconda3\\envs\\covid\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2063, in showtraceback\n",
      "    stb = self.InteractiveTB.structured_traceback(etype,\n",
      "  File \"C:\\Users\\Song1\\anaconda3\\envs\\covid\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1367, in structured_traceback\n",
      "    return FormattedTB.structured_traceback(\n",
      "  File \"C:\\Users\\Song1\\anaconda3\\envs\\covid\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1267, in structured_traceback\n",
      "    return VerboseTB.structured_traceback(\n",
      "  File \"C:\\Users\\Song1\\anaconda3\\envs\\covid\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1124, in structured_traceback\n",
      "    formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n",
      "  File \"C:\\Users\\Song1\\anaconda3\\envs\\covid\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1082, in format_exception_as_a_whole\n",
      "    last_unique, recursion_repeat = find_recursion(orig_etype, evalue, records)\n",
      "  File \"C:\\Users\\Song1\\anaconda3\\envs\\covid\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 382, in find_recursion\n",
      "    return len(records), 0\n",
      "TypeError: object of type 'NoneType' has no len()\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Song1\\anaconda3\\envs\\covid\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2061, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'TypeError' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Song1\\anaconda3\\envs\\covid\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2944, in _run_cell\n",
      "    return runner(coro)\n",
      "  File \"C:\\Users\\Song1\\anaconda3\\envs\\covid\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 68, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"C:\\Users\\Song1\\anaconda3\\envs\\covid\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3169, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"C:\\Users\\Song1\\anaconda3\\envs\\covid\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3380, in run_ast_nodes\n",
      "    self.showtraceback()\n",
      "  File \"C:\\Users\\Song1\\anaconda3\\envs\\covid\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2063, in showtraceback\n",
      "    stb = self.InteractiveTB.structured_traceback(etype,\n",
      "  File \"C:\\Users\\Song1\\anaconda3\\envs\\covid\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1367, in structured_traceback\n",
      "    return FormattedTB.structured_traceback(\n",
      "  File \"C:\\Users\\Song1\\anaconda3\\envs\\covid\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1267, in structured_traceback\n",
      "    return VerboseTB.structured_traceback(\n",
      "  File \"C:\\Users\\Song1\\anaconda3\\envs\\covid\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1142, in structured_traceback\n",
      "    formatted_exceptions += self.format_exception_as_a_whole(etype, evalue, etb, lines_of_context,\n",
      "  File \"C:\\Users\\Song1\\anaconda3\\envs\\covid\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1082, in format_exception_as_a_whole\n",
      "    last_unique, recursion_repeat = find_recursion(orig_etype, evalue, records)\n",
      "  File \"C:\\Users\\Song1\\anaconda3\\envs\\covid\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 382, in find_recursion\n",
      "    return len(records), 0\n",
      "TypeError: object of type 'NoneType' has no len()\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Song1\\anaconda3\\envs\\covid\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2061, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'TypeError' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Song1\\anaconda3\\envs\\covid\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1101, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"C:\\Users\\Song1\\anaconda3\\envs\\covid\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 248, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"C:\\Users\\Song1\\anaconda3\\envs\\covid\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 281, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"C:\\Users\\Song1\\anaconda3\\envs\\covid\\lib\\inspect.py\", line 1541, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"C:\\Users\\Song1\\anaconda3\\envs\\covid\\lib\\inspect.py\", line 1499, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"C:\\Users\\Song1\\anaconda3\\envs\\covid\\lib\\inspect.py\", line 709, in getsourcefile\n",
      "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
      "  File \"C:\\Users\\Song1\\anaconda3\\envs\\covid\\lib\\inspect.py\", line 755, in getmodule\n",
      "    os.path.realpath(f)] = module.__name__\n",
      "  File \"C:\\Users\\Song1\\anaconda3\\envs\\covid\\lib\\ntpath.py\", line 664, in realpath\n",
      "    if _getfinalpathname(spath) == path:\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "# Set 99 as missing\n",
    "\"\"\"\n",
    "output = onepl_lsrm_cont_missing(data,\n",
    "                                 ndim, niter, nburn, nthin, nprint,\n",
    "                                 jump_beta, jump_theta, jump_gamma, jump_z, jump_w,\n",
    "                                 pr_mean_beta, pr_sd_beta, pr_a_th_sigma, pr_b_th_sigma, pr_mean_theta,\n",
    "                                 pr_a_sigma, pr_b_sigma, pr_mean_gamma, pr_sd_gamma,\n",
    "                                 99)\n",
    "\"\"\"\n",
    "\n",
    "output = onepl_lsrm_cont_missing(logit_x,\n",
    "                                 ndim, niter, nburn, nthin, nprint,\n",
    "                                 jump_beta, jump_theta, jump_gamma, jump_z, jump_w,\n",
    "                                 pr_mean_beta, pr_sd_beta, pr_a_th_sigma, pr_b_th_sigma, pr_mean_theta,\n",
    "                                 pr_a_sigma, pr_b_sigma, pr_mean_gamma, pr_sd_gamma,\n",
    "                                 99)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ecc9fcc4-632d-4879-bf41-2b2bdaa82da1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['beta', 'theta', 'z', 'w', 'gamma', 'sigma_theta', 'sigma', 'map', 'accept_beta', 'accept_theta', 'accept_z', 'accept_w', 'accept_gamma'])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "ebfb7182-77fa-4199-ab24-73ef71f3b4b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def procrustes_mine(X, X_star):\n",
    "    n = X.shape[0]\n",
    "    m = X.shape[1]\n",
    "\n",
    "    J = np.identity(n)\n",
    "\n",
    "    C = X_star.transpose() @ J @ X\n",
    "    svd_out = np.linalg.svd(C)\n",
    "    R = svd_out[2] @ svd_out[0].transpose()\n",
    "    #C = udv', v@u'\n",
    "\n",
    "    s = 1\n",
    "    X_new = s * X @ R + np.zeros((n, m))\n",
    "\n",
    "    return X_new\n",
    "\n",
    "# <editor-fold desc=\"MCMC Process\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "eafdbb7f-bce6-4055-a1f1-40cb0eb5bf8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1.8622287864472156\n"
     ]
    }
   ],
   "source": [
    "nsample = data.shape[0]\n",
    "nitem  = data.shape[1]\n",
    "\n",
    "nmcmc = int((niter - nburn) / nthin)\n",
    "\n",
    "max_address = output['map'].argmax()\n",
    "\n",
    "w_star = output['w'][max_address, :, :]\n",
    "z_star = output['z'][max_address, :, :]\n",
    "\n",
    "w_proc = np.zeros((nmcmc, nitem, ndim), )\n",
    "z_proc = np.zeros((nmcmc, nsample, ndim), )\n",
    "\n",
    "for iter in range(nmcmc):\n",
    "    z_iter = output['z'][iter, :, :]\n",
    "\n",
    "    if iter != max_address:\n",
    "        z_proc[iter, :, :] = procrustes_mine(z_iter, z_star) #TODO ======= 210717 =======\n",
    "    else: \n",
    "        z_proc[iter,:,:] = z_iter\n",
    "        \n",
    "        \n",
    "\n",
    "    w_iter = output['w'][iter, :, :]\n",
    "\n",
    "    if iter != max_address:\n",
    "        w_proc[iter,:,:] = procrustes_mine(w_iter, w_star) #TODO ======= 210717 =======\n",
    "    else: \n",
    "        w_proc[iter,:,:] = w_iter\n",
    "\n",
    "\n",
    "\n",
    "w_est = np.empty((nitem, ndim))\n",
    "w_est[:] = np.nan\n",
    "\n",
    "for i in range(nitem):\n",
    "    for j in range(ndim):\n",
    "        w_est[i, j] = w_proc[:, i, j].mean()\n",
    "\n",
    "\n",
    "z_est = np.empty((nsample, ndim),)\n",
    "z_est[:] = np.nan\n",
    "\n",
    "for k in range(nsample):\n",
    "    for j in range(ndim):\n",
    "        z_est[k, j] = z_proc[:, k, j].mean()\n",
    "\n",
    "\n",
    "beta_est = output[\"beta\"].mean(axis = 0)\n",
    "theta_est = output[\"theta\"].mean(axis = 0)\n",
    "\n",
    "sigma_theta_est = output[\"sigma_theta\"].mean()\n",
    "gamma_est = output[\"gamma\"].mean()\n",
    "\n",
    "output_new = {\"beta_estimate\" : beta_est,\n",
    "              \"theta_estimate\" : theta_est,\n",
    "              \"sigma_theta_estimate\" : sigma_theta_est,\n",
    "              \"gamma_estimate\" : gamma_est,\n",
    "              \"z_estimate\" : z_est,\n",
    "              \"w_estimate\" : w_est,\n",
    "              \"beta\" : output[\"beta\"],\n",
    "              \"theta\" : output[\"theta\"],\n",
    "              \"theta_sd\" : output[\"sigma_theta\"],\n",
    "              \"gamma\" : output[\"gamma\"],\n",
    "              \"z\" : z_proc,\n",
    "              \"w\" : w_proc,\n",
    "              \"accept_beta\" : output[\"accept_beta\"],\n",
    "              \"accept_theta\" : output[\"accept_theta\"],\n",
    "              \"accept_w\" : output[\"accept_w\"],\n",
    "              \"accept_z\" : output[\"accept_z\"],\n",
    "              \"accept_gamma\" : output[\"accept_gamma\"]\n",
    "              }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9f0cae2-b9eb-401f-a0ea-c081954ab352",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## lsrm plot\n",
    "#### ggplot\n",
    "\"\"\"\n",
    "a = pd.DataFrame(output_new[\"z_estimate\"], columns=[\"coordinate_1\", \"coordinate_2\"])\n",
    "b = pd.DataFrame(output_new[\"w_estimate\"], columns=[\"coordinate_1\", \"coordinate_2\"]) #x와 w의 coordinate로 df 구성\n",
    "\n",
    "b[\"topic_name\"] = data_name\n",
    "b[\"id\"] = range(1, data_m.shape[1]+1)\n",
    "\"\"\"\n",
    "\n",
    "a = pd.DataFrame(output_new[\"z_estimate\"], columns=[\"coordinate_1\", \"coordinate_2\"])\n",
    "b = pd.DataFrame(output_new[\"w_estimate\"], columns=[\"coordinate_1\", \"coordinate_2\"]) #x와 w의 coordinate로 df 구성\n",
    "\n",
    "b[\"topic_name\"] = data_name\n",
    "b[\"id\"] = range(1, data_m.shape[1]+1)\n",
    "\n",
    "############### Rotate\n",
    "\n",
    "\n",
    "angle = -pi/30\n",
    "\n",
    "#M = pd.DataFrame( [[cos(angle), sin(angle)], [-sin(angle), cos(angle)]], columns=[\"coordinate_1\", \"coordinate_2\"])\n",
    "#print(M)\n",
    "\n",
    "M = np.array([[cos(angle), sin(angle)], [-sin(angle), cos(angle)]])\n",
    "\n",
    "# clockwise 회전용도. 따라서 일반적인 회전행렬의 inv. clockwise 기준 -6도씩 돌림.\n",
    "\n",
    "\n",
    "bnew = pd.DataFrame(np.array(-b.iloc[:, 0:2]) @ M, columns=[\"coordinate_1\", \"coordinate_2\"])\n",
    "bnew[\"topic_name\"] = b[\"topic_name\"]\n",
    "bnew[\"id\"] = b[\"id\"]\n",
    "\n",
    "\n",
    "#-b.iloc[:, 0:2].dot(M)\n",
    "\n",
    "#bnew = (-b.iloc[:, 1:2]) @ (M) #TODO =========================================== #\n",
    "#bnew = data.frame(as.matrix(-b[, 1:2]) % * % M)\n",
    "#bnew = data.frame(as.matrix(-b[,2:1]) %*% M) # for 75, 70 # 계수 컬럼1과 컬럼2가 교환됨. for what?\n",
    "\n",
    "anew = pd.DataFrame(np.array(-a.iloc[:, 0:2]) @ M, columns=[\"coordinate_1\", \"coordinate_2\"]) #TODO ===========================================\n",
    "#anew = (-a[:, 2:1]).dot(M)  # for 75\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "b = bnew\n",
    "a = anew\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "a113e211-52b6-4f00-ac76-5c5a13bf456a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>coordinate_1</th>\n",
       "      <th>coordinate_2</th>\n",
       "      <th>dist</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [coordinate_1, coordinate_2, dist]\n",
       "Index: []"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "################################################## TODO distance\n",
    "\n",
    "\n",
    "a[\"dist\"] = (a[\"coordinate_1\"]**2 + a[\"coordinate_2\"]**2)**0.5\n",
    "\n",
    "a\n",
    "\n",
    "#head(a)\n",
    "#hist(a$dist)\n",
    "#summary(a$dist)\n",
    "#quantile(a$dist, c(0.8, 0.9))\n",
    "\n",
    "\n",
    "a_new = a.loc[a[\"dist\"]>1.5, :]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "c8a5e0cd-9b50-47bc-8105-cde141137c7d",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 1, 1, 0, 0, 0, 1, 2, 1, 2, 1, 0, 2, 2, 2, 2, 3, 3, 3, 0, 3, 3,\n",
       "       2, 3, 1, 2, 2, 2, 2, 0, 1, 3, 3, 1, 0, 1, 2, 1, 0, 2, 2, 3, 0, 3,\n",
       "       0, 2, 0, 1, 0, 0, 2, 1, 0, 2, 2, 2, 3, 0, 0, 0, 3, 0, 0, 1, 1, 3,\n",
       "       0, 3, 2, 1, 1, 0, 2, 2, 1, 0, 3, 2, 2, 2, 0, 0, 0, 0, 0, 3, 0, 3,\n",
       "       0, 0, 0, 2, 3, 2, 2, 0, 1, 2, 3, 0, 0, 1, 1, 3, 1, 2, 2, 2, 3, 1,\n",
       "       2, 2, 1, 0, 3, 0, 0, 0, 3, 2, 2, 1, 2, 3, 0, 1, 2, 2, 2, 3, 0, 3,\n",
       "       3, 0, 2, 2, 2, 0, 2, 0, 3, 0, 0, 3, 2, 1, 2, 2, 3, 0, 3, 1, 0, 1,\n",
       "       3, 2, 0, 3, 0, 2, 1, 2, 0, 3, 3, 0, 0, 2, 2, 0, 1, 3, 0, 2, 1, 1,\n",
       "       1, 2, 2, 2, 0, 2, 2, 1, 3, 2, 3, 0, 1, 2, 0, 3, 2, 2, 0, 1, 3, 0,\n",
       "       1, 2, 3, 3, 0, 2, 1, 1, 3, 2, 2, 0, 0, 2, 2, 1, 3, 3, 2, 2, 3, 3,\n",
       "       0, 0, 1, 2, 0, 1, 2, 0, 2, 1, 0, 2, 3, 3, 2, 1, 2, 0, 2, 0, 3, 3,\n",
       "       1, 1, 2, 1, 0, 0, 0, 2, 1, 1, 2, 2, 1, 2, 2, 2, 0, 2, 3, 0, 3, 0,\n",
       "       1, 1, 0, 0, 3, 2, 3, 3, 3, 0, 1, 0, 0, 1, 3, 0, 2, 1, 3, 3, 1, 3,\n",
       "       0, 2, 2, 1, 3, 3, 3, 0, 1, 0, 0, 0, 2, 2, 3, 1, 0, 3, 3, 2, 3, 2,\n",
       "       2, 2, 1, 3, 3, 0, 2, 2, 1, 1, 1, 1, 1, 1, 3, 2, 0, 2, 2, 3, 0, 0,\n",
       "       0, 0, 2, 3, 2, 1, 3, 1, 0, 0, 1, 0, 2, 0, 0, 3, 2, 0, 3, 3, 2, 2,\n",
       "       1, 0, 0, 0, 3, 2, 3, 3, 0, 1, 0, 2, 2, 2, 0, 3, 3, 0, 1, 1, 2, 3,\n",
       "       2, 2, 0, 0, 1, 2, 3, 1, 1, 0, 0, 2, 2, 1, 2, 1, 0, 3, 2, 2, 1, 1,\n",
       "       1, 1, 0, 2, 3, 2, 2, 1, 0, 2, 3, 3, 0, 1, 3, 0, 1, 1, 2, 3, 1, 0,\n",
       "       0, 0, 2, 2, 3, 2, 0, 1, 2, 2, 2, 0, 2, 2, 2, 3, 0, 1, 0, 2, 0, 2,\n",
       "       2, 2, 3, 2, 0, 0, 0, 1, 1, 0, 0, 3, 0, 2, 1, 0, 3, 0, 3, 3, 2, 2,\n",
       "       3, 2, 0, 2, 0, 2, 3, 3, 1, 2, 3, 2, 3, 2, 2, 1, 1, 3, 2, 2, 1, 0,\n",
       "       1, 2, 1, 0, 0, 3, 0, 0, 2, 2, 3, 2, 2, 0, 2, 3, 2, 3, 2, 2, 1, 0,\n",
       "       1, 0, 0, 3, 2, 0, 0, 3, 1, 1, 2, 3, 0, 1, 3, 0, 0, 3, 0, 0, 3, 0,\n",
       "       0, 0, 0, 0, 1, 1, 1, 2, 3, 3, 2, 2, 3, 2, 2, 2, 2, 2, 3, 1])"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "####################### TODO: 3dplot\n",
    "\n",
    "#par(mfrow=c(1, 1))\n",
    "#library(scatterplot3d)\n",
    "\n",
    "new = pd.DataFrame({\"x\" : b[\"coordinate_1\"],\n",
    "                   \"y\" : b[\"coordinate_2\"],\n",
    "                   \"z\" : output_new[\"beta_estimate\"],\n",
    "                   \"topics\" : b[\"topic_name\"]}) #word의 계수1, word의 계수2, beta의 측정치, word의 topic name,\n",
    "                                                #output_new는 z_est, w_est, z.proc, w.proc으로 바꾼버전\n",
    "\n",
    "word_cluster = KMeans(n_clusters=4).fit(output_new[\"z_estimate\"])\n",
    "word_cluster.labels_\n",
    "\n",
    "topic_cluster = KMeans(n_clusters=4).fit(b.iloc[:, 0:2])\n",
    "topic_cluster.labels_\n",
    "\n",
    "\n",
    "\n",
    "#colors = topic_cluster[\"cluster\"]\n",
    "#topic_plot = scatterplot3d(new[, 1:3],\n",
    "                           pch=16,\n",
    "                           color=colors,\n",
    "                           angle=50)  # TODO =================================\n",
    "# word_plot$points3d(output_new$w_estimate,pch=8,color=color2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "09632efa-f73c-41bc-9085-0b1423ea0d6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>coordinate_1</th>\n",
       "      <th>coordinate_2</th>\n",
       "      <th>topic_name</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.423824</td>\n",
       "      <td>0.673819</td>\n",
       "      <td>Outbreak</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.070232</td>\n",
       "      <td>0.325487</td>\n",
       "      <td>Emotional.Effect</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.066860</td>\n",
       "      <td>-0.236272</td>\n",
       "      <td>Symptom</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.492909</td>\n",
       "      <td>-1.231272</td>\n",
       "      <td>Hospital.Related</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.419349</td>\n",
       "      <td>-0.141562</td>\n",
       "      <td>Immune.Reaction</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.258069</td>\n",
       "      <td>1.148658</td>\n",
       "      <td>Disease.Relations</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>-0.989446</td>\n",
       "      <td>1.572048</td>\n",
       "      <td>Policy</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>-1.417868</td>\n",
       "      <td>-0.055144</td>\n",
       "      <td>Psychological.Problem</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>-1.061147</td>\n",
       "      <td>-0.319857</td>\n",
       "      <td>Analysis.of.Transmission</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.494012</td>\n",
       "      <td>1.052818</td>\n",
       "      <td>Cardiovascular.System</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.190649</td>\n",
       "      <td>-1.779199</td>\n",
       "      <td>Protective.Equipment</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.324209</td>\n",
       "      <td>-1.604040</td>\n",
       "      <td>Anosmia</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>-0.330860</td>\n",
       "      <td>-0.735695</td>\n",
       "      <td>Respiratory.System</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1.231658</td>\n",
       "      <td>0.171649</td>\n",
       "      <td>Treatment</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.003656</td>\n",
       "      <td>-1.755873</td>\n",
       "      <td>Diagnosis</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>-0.534675</td>\n",
       "      <td>1.563378</td>\n",
       "      <td>Virus.Analysis</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.294194</td>\n",
       "      <td>0.568805</td>\n",
       "      <td>Virus.Defense.Mechanism</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.421138</td>\n",
       "      <td>-1.187214</td>\n",
       "      <td>Literature.Analysis</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>-0.880290</td>\n",
       "      <td>-0.941197</td>\n",
       "      <td>Microbiome.</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>-0.027373</td>\n",
       "      <td>0.430398</td>\n",
       "      <td>Immune.System</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    coordinate_1  coordinate_2                topic_name  id\n",
       "0      -1.423824      0.673819                  Outbreak   1\n",
       "1       0.070232      0.325487          Emotional.Effect   2\n",
       "2       1.066860     -0.236272                   Symptom   3\n",
       "3       0.492909     -1.231272          Hospital.Related   4\n",
       "4      -1.419349     -0.141562           Immune.Reaction   5\n",
       "5       0.258069      1.148658         Disease.Relations   6\n",
       "6      -0.989446      1.572048                    Policy   7\n",
       "7      -1.417868     -0.055144     Psychological.Problem   8\n",
       "8      -1.061147     -0.319857  Analysis.of.Transmission   9\n",
       "9       0.494012      1.052818     Cardiovascular.System  10\n",
       "10      0.190649     -1.779199      Protective.Equipment  11\n",
       "11      0.324209     -1.604040                   Anosmia  12\n",
       "12     -0.330860     -0.735695        Respiratory.System  13\n",
       "13      1.231658      0.171649                 Treatment  14\n",
       "14      0.003656     -1.755873                 Diagnosis  15\n",
       "15     -0.534675      1.563378            Virus.Analysis  16\n",
       "16      0.294194      0.568805   Virus.Defense.Mechanism  17\n",
       "17      0.421138     -1.187214       Literature.Analysis  18\n",
       "18     -0.880290     -0.941197               Microbiome.  19\n",
       "19     -0.027373      0.430398             Immune.System  20"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wcss = [1, 2]\n",
    "bet_tot = [1, 2]\n",
    "bet = [1, 2]\n",
    "\n",
    "ncluster = 5\n",
    "\n",
    "data_set2 = data_m\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import scale\n",
    "from scipy.spatial.distance import euclidean\n",
    "\n",
    "\n",
    "####################################################################################\n",
    "\n",
    "\n",
    "def affinityMatrix(dif, K=20, sigma=0.5):\n",
    "    diff = np.array(dif)\n",
    "    \n",
    "    N = diff.shape[0]\n",
    "    diff = (diff + diff.transpose()) / 2\n",
    "    np.fill_diagonal(diff, 0)\n",
    "    sortedColumns = np.apply_along_axis(sorted, 0, diff).transpose()\n",
    "\n",
    "    def finiteMean(x):\n",
    "        return x[np.isfinite(x)].mean()\n",
    "    \n",
    "    eps = np.finfo(\"double\").eps\n",
    "\n",
    "    means = np.apply_along_axis(finiteMean, 1, sortedColumns[:, 0:K + 1]) + eps\n",
    "    Sig = np.mean.outer(means, means) / 3 * 2 + diff / 3 + eps\n",
    "    Sig[Sig <= eps] = eps\n",
    "\n",
    "    densities = scipy.stats.norm.pdf(diff, 0, sigma * Sig)\n",
    "\n",
    "    W = (densities + densities.transpose()) / 2\n",
    "    \n",
    "    return W\n",
    "\n",
    "\n",
    "####################################################################################\n",
    "\n",
    "\n",
    "for aa in range(2, (ncol(data_set2))-1):\n",
    "    X = b.iloc[:, 0:2]\n",
    "    #X = ex\n",
    "    idist = np.zeros((X.shape[0], X.shape[0]))\n",
    "\n",
    "    for i in range(X.shape[0]):\n",
    "        for j in range(X.shape[0]):\n",
    "            idist[i, j] = np.linalg.norm(X[i, :] - X[j, :]) \n",
    "            #euclidean(X[:, i], X[:, j])\n",
    "            continue\n",
    "\n",
    "    W = affinityMatrix(idist, K=aa)  # TODO =====================\n",
    "    d = W.sum(axis=1)\n",
    "\n",
    "    d[d == 0] = np.finfo(\"double\").eps\n",
    "\n",
    "    D = np.diag(d)\n",
    "\n",
    "    L = D - W\n",
    "    Di = np.diag(1 / sqrt(d))\n",
    "\n",
    "    NL = Di @ L @ Di\n",
    "    ev = np.linalg.eig(NL)[0]\n",
    "    evec = np.linalg.eig(NL)[1]\n",
    "\n",
    "    ix = pd.Index(abs(ev)).sort_values(return_indexer=True)[1]\n",
    "    U = evec[:, ix[0:ncluster]]\n",
    "\n",
    "\n",
    "    def normalize(x):\n",
    "        return x / sqrt(sum(x ^ 2))\n",
    "\n",
    "\n",
    "    U.apply(normalize, 1)\n",
    "\n",
    "    final = KMeans(n_clusters=ncluster, random_state=0).fit(U)\n",
    "    group = final.labels_\n",
    "\n",
    "    totss = sum(sum(scale(X, axis=0, with_std=False) ** 2))\n",
    "    tot_withinss = final.inertia_\n",
    "    betweenss = totss - tot_withinss\n",
    "\n",
    "    wcss[aa] = tot_withinss  # min #3:82%, 4: 61%, 5: 91%, 6:86%. 7:83%. 8: 85%, 9: 86%. 10: 87%\n",
    "    bet_tot[aa] = betweenss / totss * 100  # max\n",
    "    bet[aa] = betweenss\n",
    "\n",
    "    # wcss[aa] < - final$tot.withinss  # min #3:82%, 4: 61%, 5: 91%, 6:86%. 7:83%. 8: 85%, 9: 86%. 10: 87%\n",
    "    # bet_tot[aa] < - final$betweenss / final$totss * 100  # max\n",
    "    # bet[aa] < - final$betweenss\n",
    "\n",
    "# which.max(bet_tot)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44dc95ce-4694-43bd-8119-214c6f87bf41",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# TODO =====================\n",
    "W = affinityMatrix(idist, K=which.max(bet_tot))  # TODO =====================\n",
    "\n",
    "## cluster the topic using select number of cluster\n",
    "# ncluster <- min(k)  # TODO =====================\n",
    "ncluster = 3  # TODO =====================\n",
    "\n",
    "\n",
    "group_index = c()\n",
    "\n",
    "for i in range(1, max(group) + 1):\n",
    "    group_index[i] = min(np.where(group == i))\n",
    "\n",
    "# TODO ====================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "521dc3f6-df59-409e-a028-635ff2e82209",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "word_position = pd.concat([data_word, a.iloc[:, 0:2]], axis=1)\n",
    "word_position[\"dist\"] = (word_position[\"coordinate_1\"] ** 2 + word_position[\"coordinate_2\"] ** 2) ** 0.5\n",
    "word_new = word_position.loc[word_position[\"dist\"] > 1.4, :]\n",
    "\n",
    "\n",
    "#quantile(word_position$dist, c(0.05, 0.2))\n",
    "word_new = word_position[word_position[\"dist\"] < 0.41,]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89505ceb-10e3-46a1-9aa6-bab223e59d43",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "words = data_word\n",
    "close_word_index = []\n",
    "\n",
    "## cosine similarity\n",
    "\n",
    "temp = pd.concat([b.iloc[:, 0:2], group], axis=1)\n",
    "\n",
    "\n",
    "# head(temp)\n",
    "\n",
    "## center of topic group\n",
    "\n",
    "\n",
    "# temp2 = data.frame(temp % > % group_by(group) % > % summarise(x=mean(coordinate_1), y=mean(coordinate_2)))\n",
    "\n",
    "temp2 = temp.groupby(\"group\", axis=1).agg({\"coordinate_1\": \"mean\", \n",
    "                                           \"coordinate_2\": \"mean\"})\n",
    "temp2.columns = [\"x\", \"y\"]\n",
    "\n",
    "# head(temp2)\n",
    "\n",
    "word_position = pd.concat([words, a[, 0:2]], axis=1)\n",
    "close_word_index = []\n",
    "\n",
    "for(i in 1:ncol(data_set2)){\n",
    "  ## here 10\n",
    "  #i = 1\n",
    "  close_word_index[[i]] <- order(as.matrix(dist(rbind(b[i,1:2], a[,1:2])))[1,-1])[1:25]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "c13d96a1-c06c-477a-8326-8eb33e6d6c14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 1, 1, 0, 0, 0, 1, 2, 1, 2, 1, 0, 2, 2, 2, 2, 3, 3, 3, 0, 3, 3,\n",
       "       2, 3, 1, 2, 2, 2, 2, 0, 1, 3, 3, 1, 0, 1, 2, 1, 0, 2, 2, 3, 0, 3,\n",
       "       0, 2, 0, 1, 0, 0, 2, 1, 0, 2, 2, 2, 3, 0, 0, 0, 3, 0, 0, 1, 1, 3,\n",
       "       0, 3, 2, 1, 1, 0, 2, 2, 1, 0, 3, 2, 2, 2, 0, 0, 0, 0, 0, 3, 0, 3,\n",
       "       0, 0, 0, 2, 3, 2, 2, 0, 1, 2, 3, 0, 0, 1, 1, 3, 1, 2, 2, 2, 3, 1,\n",
       "       2, 2, 1, 0, 3, 0, 0, 0, 3, 2, 2, 1, 2, 3, 0, 1, 2, 2, 2, 3, 0, 3,\n",
       "       3, 0, 2, 2, 2, 0, 2, 0, 3, 0, 0, 3, 2, 1, 2, 2, 3, 0, 3, 1, 0, 1,\n",
       "       3, 2, 0, 3, 0, 2, 1, 2, 0, 3, 3, 0, 0, 2, 2, 0, 1, 3, 0, 2, 1, 1,\n",
       "       1, 2, 2, 2, 0, 2, 2, 1, 3, 2, 3, 0, 1, 2, 0, 3, 2, 2, 0, 1, 3, 0,\n",
       "       1, 2, 3, 3, 0, 2, 1, 1, 3, 2, 2, 0, 0, 2, 2, 1, 3, 3, 2, 2, 3, 3,\n",
       "       0, 0, 1, 2, 0, 1, 2, 0, 2, 1, 0, 2, 3, 3, 2, 1, 2, 0, 2, 0, 3, 3,\n",
       "       1, 1, 2, 1, 0, 0, 0, 2, 1, 1, 2, 2, 1, 2, 2, 2, 0, 2, 3, 0, 3, 0,\n",
       "       1, 1, 0, 0, 3, 2, 3, 3, 3, 0, 1, 0, 0, 1, 3, 0, 2, 1, 3, 3, 1, 3,\n",
       "       0, 2, 2, 1, 3, 3, 3, 0, 1, 0, 0, 0, 2, 2, 3, 1, 0, 3, 3, 2, 3, 2,\n",
       "       2, 2, 1, 3, 3, 0, 2, 2, 1, 1, 1, 1, 1, 1, 3, 2, 0, 2, 2, 3, 0, 0,\n",
       "       0, 0, 2, 3, 2, 1, 3, 1, 0, 0, 1, 0, 2, 0, 0, 3, 2, 0, 3, 3, 2, 2,\n",
       "       1, 0, 0, 0, 3, 2, 3, 3, 0, 1, 0, 2, 2, 2, 0, 3, 3, 0, 1, 1, 2, 3,\n",
       "       2, 2, 0, 0, 1, 2, 3, 1, 1, 0, 0, 2, 2, 1, 2, 1, 0, 3, 2, 2, 1, 1,\n",
       "       1, 1, 0, 2, 3, 2, 2, 1, 0, 2, 3, 3, 0, 1, 3, 0, 1, 1, 2, 3, 1, 0,\n",
       "       0, 0, 2, 2, 3, 2, 0, 1, 2, 2, 2, 0, 2, 2, 2, 3, 0, 1, 0, 2, 0, 2,\n",
       "       2, 2, 3, 2, 0, 0, 0, 1, 1, 0, 0, 3, 0, 2, 1, 0, 3, 0, 3, 3, 2, 2,\n",
       "       3, 2, 0, 2, 0, 2, 3, 3, 1, 2, 3, 2, 3, 2, 2, 1, 1, 3, 2, 2, 1, 0,\n",
       "       1, 2, 1, 0, 0, 3, 0, 0, 2, 2, 3, 2, 2, 0, 2, 3, 2, 3, 2, 2, 1, 0,\n",
       "       1, 0, 0, 3, 2, 0, 0, 3, 1, 1, 2, 3, 0, 1, 3, 0, 0, 3, 0, 0, 3, 0,\n",
       "       0, 0, 0, 0, 1, 1, 1, 2, 3, 3, 2, 2, 3, 2, 2, 2, 2, 2, 3, 1])"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##### Cluster_Group near words\n",
    "\n",
    "#head(word_position)\n",
    "\n",
    "for i in range(temp2.shape[0]):\n",
    "    #i = 1\n",
    "    ## here 10\n",
    "    cluster_word_dist = []\n",
    "    close_word_index = []\n",
    "    \n",
    "    np.delete(temp2, 0, 1)[i, :]\n",
    "    \n",
    "    for k in nrow(output_new[\"z_estimate\"].shape[0]:\n",
    "                  cluster_word_dist[k] = np.linalg.norm(np.delete(temp2, 0, 1)[i, :] - \n",
    "                                                        output_new[\"z_estimate\"][k, :])\n",
    "    \n",
    "    close_word_index = order(as.matrix(cluster_word_dist))[1:25]\n",
    "    \n",
    "\n",
    "save.image(\"75_result.RData\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e600c8aa-c18a-48a8-b9e8-ca6f4c3305f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from pyarma import *\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "35bf3ea0-5729-4dc4-b9d0-19505d226441",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\n",
      "   1.2947   1.4712   1.6029   1.5053\n",
      "   2.2507   1.6893   1.9306   2.2118\n",
      "   1.8974   2.0922   2.3306   2.1280\n",
      "   1.9538   1.5569   1.6389   2.1417\n"
     ]
    }
   ],
   "source": [
    "A = mat(4, 5, fill.randu)\n",
    "B = mat(4, 5, fill.randu)\n",
    "  \n",
    "C = A*B.t()\n",
    "\n",
    "C.print(\"C:\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
